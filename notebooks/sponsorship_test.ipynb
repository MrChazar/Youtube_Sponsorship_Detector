{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Próba wykrycia sponsoringu\n",
    "Spróbuję pobrać film, pobrać jego ścieżkę dźwiękową, pobrać tekst z tego dźwięku i wykryć sponsoring za pomocą modelu językowego"
   ],
   "id": "e712a36ffa15a08a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pobranie materiału na yt\n",
    "Skorzystam z biblioteki z yt_dlp"
   ],
   "id": "f271988e9c7b3068"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:39:11.653322Z",
     "start_time": "2025-04-12T07:38:11.732109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yt_dlp\n",
    "video_title = \"video\"\n",
    "url = 'https://youtu.be/9pXIFqrXW3k'\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'outtmpl': f'{video_title}',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'noplaylist': True,\n",
    "}\n",
    "\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    info = ydl.extract_info(url, download=False)\n",
    "    ydl.download([url])"
   ],
   "id": "dd23c46814eac7d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/9pXIFqrXW3k\n",
      "[youtube] 9pXIFqrXW3k: Downloading webpage\n",
      "[youtube] 9pXIFqrXW3k: Downloading tv client config\n",
      "[youtube] 9pXIFqrXW3k: Downloading player 9599b765\n",
      "[youtube] 9pXIFqrXW3k: Downloading tv player API JSON\n",
      "[youtube] 9pXIFqrXW3k: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 9pXIFqrXW3k: Signature extraction failed: Some formats may be missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 9pXIFqrXW3k: Downloading m3u8 information\n",
      "[youtube] Extracting URL: https://youtu.be/9pXIFqrXW3k\n",
      "[youtube] 9pXIFqrXW3k: Downloading webpage\n",
      "[youtube] 9pXIFqrXW3k: Downloading tv client config\n",
      "[youtube] 9pXIFqrXW3k: Downloading tv player API JSON\n",
      "[youtube] 9pXIFqrXW3k: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 9pXIFqrXW3k: Signature extraction failed: Some formats may be missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 9pXIFqrXW3k: Downloading m3u8 information\n",
      "[info] 9pXIFqrXW3k: Downloading 1 format(s): 234\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 353\n",
      "[download] Destination: video\n",
      "[download] 100% of   26.67MiB in 00:00:37 at 734.22KiB/s                 \n",
      "[ExtractAudio] Destination: video.mp3\n",
      "Deleting original file video (pass -k to keep)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wczytanie pliku i konwersja na wav\n",
    "(wymaga to pobranie ffmpega lokalnie za pomocą komendy winget install ffmpeg)\n",
    "(dla linuxa to samo tylko no przez jakiś tam zarządzacz pakietami)"
   ],
   "id": "723ae56212b6dce0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:39:12.802494Z",
     "start_time": "2025-04-12T07:39:11.653322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import soundfile as sf"
   ],
   "id": "26c5b0c2ef58c6b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:38:07.888713Z",
     "start_time": "2025-04-12T07:38:07.659486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konwersja MP3 do WAV za pomocą ffmpeg\n",
    "mp3_path = f'{video_title}.mp3'\n",
    "wav_path = f'{video_title}.wav'\n",
    "subprocess.run(['ffmpeg', '-i', mp3_path, '-ar', '16000', '-ac', '1', wav_path])\n",
    "\n",
    "# Wczytywanie pliku WAV\n",
    "y, sr = sf.read(wav_path)\n",
    "y = y.tolist()\n",
    "\n",
    "# Wyświetlenie informacji\n",
    "print(f\"Częstotliwość próbkowania: {sr} Hz\")\n",
    "print(f\"Długość sygnału: {len(y)} próbek\")\n",
    "\n",
    "# Wykres sygnału audio\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y)\n",
    "plt.title('Sygnał audio')\n",
    "plt.xlabel('Próbki')\n",
    "plt.ylabel('Amplituda')\n",
    "plt.show()"
   ],
   "id": "8bee7d86cdf97895",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_title' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Konwersja MP3 do WAV za pomocą ffmpeg\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m mp3_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mvideo_title\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.mp3\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      3\u001B[0m wav_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvideo_title\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.wav\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      4\u001B[0m subprocess\u001B[38;5;241m.\u001B[39mrun([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mffmpeg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-i\u001B[39m\u001B[38;5;124m'\u001B[39m, mp3_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-ar\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m16000\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-ac\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m'\u001B[39m, wav_path])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'video_title' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wyciągnięcia z dźwięku tekstu\n",
    "Próbowałem paru różnych narzędzi i chyba wybiorę tego whispera"
   ],
   "id": "7f9d535ec9b34da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Vosk\n",
    "- Wolne\n",
    "- Przy większym modelu (badałem duży i mały) jakość wykrytego tekstu git\n",
    "\n",
    "Rozwiązanie nie do skorzystania"
   ],
   "id": "da5ab948ac711384"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:38:07.893628100Z",
     "start_time": "2025-03-16T19:00:28.481579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import vosk\n",
    "import wave\n",
    "import time\n",
    "\n",
    "model = vosk.Model(\"vosk/vosk-model-en-us-0.42-gigaspeech\")\n",
    "audio_file = \"video_6.wav\"\n",
    "wf = wave.open(audio_file, \"rb\")\n",
    "recognizer = vosk.KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "buffer_size = 16000\n",
    "start_time = time.time()\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    data = wf.readframes(buffer_size)\n",
    "    if len(data) == 0 or iteration >= 100:\n",
    "        break\n",
    "    recognizer.AcceptWaveform(data)\n",
    "    iteration += 1\n",
    "    print(f\"Iteracja {iteration}: {time.time() - start_time:.2f} sekund\")\n",
    "\n",
    "result = recognizer.FinalResult()\n",
    "print(\"Transkrypcja:\", result)"
   ],
   "id": "890c2d6212fd8ae3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracja 1: 1.09 sekund\n",
      "Iteracja 2: 2.84 sekund\n",
      "Iteracja 3: 5.05 sekund\n",
      "Iteracja 4: 6.89 sekund\n",
      "Iteracja 5: 8.59 sekund\n",
      "Iteracja 6: 10.24 sekund\n",
      "Iteracja 7: 11.90 sekund\n",
      "Iteracja 8: 13.62 sekund\n",
      "Iteracja 9: 15.62 sekund\n",
      "Iteracja 10: 17.16 sekund\n",
      "Iteracja 11: 18.84 sekund\n",
      "Iteracja 12: 20.52 sekund\n",
      "Iteracja 13: 21.65 sekund\n",
      "Iteracja 14: 22.02 sekund\n",
      "Iteracja 15: 22.51 sekund\n",
      "Iteracja 16: 22.88 sekund\n",
      "Iteracja 17: 23.24 sekund\n",
      "Iteracja 18: 23.61 sekund\n",
      "Iteracja 19: 23.96 sekund\n",
      "Iteracja 20: 24.31 sekund\n",
      "Iteracja 21: 24.75 sekund\n",
      "Iteracja 22: 25.10 sekund\n",
      "Iteracja 23: 25.45 sekund\n",
      "Iteracja 24: 25.80 sekund\n",
      "Iteracja 25: 26.17 sekund\n",
      "Iteracja 26: 26.53 sekund\n",
      "Iteracja 27: 26.98 sekund\n",
      "Iteracja 28: 27.37 sekund\n",
      "Iteracja 29: 27.75 sekund\n",
      "Iteracja 30: 28.14 sekund\n",
      "Iteracja 31: 28.51 sekund\n",
      "Iteracja 32: 28.87 sekund\n",
      "Iteracja 33: 29.30 sekund\n",
      "Iteracja 34: 29.68 sekund\n",
      "Iteracja 35: 30.03 sekund\n",
      "Iteracja 36: 30.39 sekund\n",
      "Iteracja 37: 30.74 sekund\n",
      "Iteracja 38: 31.12 sekund\n",
      "Iteracja 39: 31.58 sekund\n",
      "Iteracja 40: 31.96 sekund\n",
      "Iteracja 41: 32.34 sekund\n",
      "Iteracja 42: 32.71 sekund\n",
      "Iteracja 43: 33.09 sekund\n",
      "Iteracja 44: 33.46 sekund\n",
      "Iteracja 45: 33.92 sekund\n",
      "Iteracja 46: 34.30 sekund\n",
      "Iteracja 47: 34.68 sekund\n",
      "Iteracja 48: 35.06 sekund\n",
      "Iteracja 49: 35.42 sekund\n",
      "Iteracja 50: 35.82 sekund\n",
      "Iteracja 51: 36.29 sekund\n",
      "Iteracja 52: 36.67 sekund\n",
      "Iteracja 53: 37.06 sekund\n",
      "Iteracja 54: 37.44 sekund\n",
      "Iteracja 55: 37.81 sekund\n",
      "Iteracja 56: 38.19 sekund\n",
      "Iteracja 57: 38.66 sekund\n",
      "Iteracja 58: 39.00 sekund\n",
      "Iteracja 59: 39.86 sekund\n",
      "Iteracja 60: 41.57 sekund\n",
      "Iteracja 61: 43.32 sekund\n",
      "Iteracja 62: 45.03 sekund\n",
      "Iteracja 63: 47.15 sekund\n",
      "Iteracja 64: 48.84 sekund\n",
      "Iteracja 65: 50.52 sekund\n",
      "Iteracja 66: 52.22 sekund\n",
      "Iteracja 67: 53.94 sekund\n",
      "Iteracja 68: 55.66 sekund\n",
      "Iteracja 69: 57.82 sekund\n",
      "Iteracja 70: 59.52 sekund\n",
      "Iteracja 71: 61.23 sekund\n",
      "Iteracja 72: 62.93 sekund\n",
      "Iteracja 73: 64.63 sekund\n",
      "Iteracja 74: 66.30 sekund\n",
      "Iteracja 75: 68.43 sekund\n",
      "Iteracja 76: 70.28 sekund\n",
      "Iteracja 77: 72.10 sekund\n",
      "Iteracja 78: 73.85 sekund\n",
      "Iteracja 79: 75.57 sekund\n",
      "Iteracja 80: 77.27 sekund\n",
      "Iteracja 81: 79.25 sekund\n",
      "Iteracja 82: 80.90 sekund\n",
      "Iteracja 83: 82.48 sekund\n",
      "Iteracja 84: 84.04 sekund\n",
      "Iteracja 85: 85.67 sekund\n",
      "Iteracja 86: 87.31 sekund\n",
      "Iteracja 87: 89.29 sekund\n",
      "Iteracja 88: 90.97 sekund\n",
      "Iteracja 89: 92.69 sekund\n",
      "Iteracja 90: 94.39 sekund\n",
      "Iteracja 91: 96.08 sekund\n",
      "Iteracja 92: 97.73 sekund\n",
      "Iteracja 93: 99.90 sekund\n",
      "Iteracja 94: 101.52 sekund\n",
      "Iteracja 95: 103.14 sekund\n",
      "Iteracja 96: 104.79 sekund\n",
      "Iteracja 97: 106.43 sekund\n",
      "Iteracja 98: 108.27 sekund\n",
      "Iteracja 99: 110.39 sekund\n",
      "Iteracja 100: 111.96 sekund\n",
      "Transkrypcja: {\n",
      "  \"text\" : \"this is around the forest a powerful machine learning algorithm based on decision trees and the stennis a sport i'm kind of obsessed with in this video i'll build a random forest throw out a bunch of dennis data and then make it for the tennis match outcomes and predict the winner of a big tennis tournament and we'll see how it performs but first i need data i won a lot of data i want every single breakpoint every single double surf every single double fold i want everything their backhands and forehands their heights their ages their dad's name their mom saved their groma secret lasagna recipe yeah i need that stuff to men i'm surviving on noodles over here and then i found it the holy grail of tennis datasets a filed so massive so detailed that opening it crashed my computer someone three statisticians and made my actual bag for mercy the famous two thousand and eight wimbledon final between rafa nadal and roger federer i got it the longest grand slam final of all time i got it even this one time this kid bid rafa nadal novak djokovic back-to-back a habit i have it all i have every single atp association of tennis professionals match from nineteen eighty one to twenty twenty four baby but before using this data i want to try building a decision tree from scratch that's right no se lower no pi torch just my girlfriend named by me and decision trees are pretty awesome think of them like a chose your own adventure book but instead of deciding whether you fight a dragon or a runaway it's the siding who want a tennis match let's take that titanic disaster as an example we've got a lot of data on passengers things like their age their cabin and ticket class as you didn't create works by asking a series of yes and no questions\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Whisper-Small\n",
    "- Działa na równo z trwaniem mateirału o wieeeeeeele za wolno\n",
    "- Jakość wykrytego tekstu jest zadowalająca\n",
    "- Jakość timestampów jest fatalna i nie przyda nam się to chyba że ktoś ogarnie jak to zmienić\n",
    "- Dostajemy wynik w formacie który możemy wykorzystać dalej\n",
    "- Na plus jest też to że wystarczy sama ścieżka do pliku wav by model mógł analizować dźwięk ale pewnie i tak będziemy chcieli jakoś ffmpegiem ten dźwięk modyfikować więc zostawie to póki co\n"
   ],
   "id": "17c134618a79bbb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:38:07.893628100Z",
     "start_time": "2025-03-23T20:05:05.710035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# pobranie modelu\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-medium.en\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    token=\"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\"\n",
    ")\n",
    "\n",
    "# uruchomienie modelu\n",
    "result = pipe(wav_path, return_timestamps=True)\n",
    "print(f\"Surowy wynik {result}\")\n",
    "\n",
    "result['chunks'] = sorted(result['chunks'], key=lambda x: x['timestamp'][0])\n",
    "\n",
    "text = \"\"\n",
    "print(\"Timestampy:\")\n",
    "for segment in result['chunks']:\n",
    "    text +=f\"{segment['timestamp']}, Tekst: {segment['text']}\\n\""
   ],
   "id": "e4d4c45bd09ba2a0",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 14\u001B[0m\n\u001B[0;32m      6\u001B[0m pipe \u001B[38;5;241m=\u001B[39m pipeline(\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautomatic-speech-recognition\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      8\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai/whisper-medium.en\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      9\u001B[0m     device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     token\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhf_yiIkrwdKRcalSrZFfaBscAjogAVoDhUEqD\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     11\u001B[0m )\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# uruchomienie modelu\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwav_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_timestamps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSurowy wynik \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     17\u001B[0m result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunks\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchunks\u001B[39m\u001B[38;5;124m'\u001B[39m], key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:292\u001B[0m, in \u001B[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001B[1;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    231\u001B[0m     inputs: Union[np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;28mbytes\u001B[39m, \u001B[38;5;28mstr\u001B[39m],\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    233\u001B[0m ):\n\u001B[0;32m    234\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;124;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001B[39;00m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;124;03m    documentation for more information.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;124;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001B[39;00m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 292\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\base.py:1154\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001B[0;32m   1153\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ChunkPipeline):\n\u001B[1;32m-> 1154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_iterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m                \u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001B[0m, in \u001B[0;36mPipelineIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader_batch_item()\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[1;32m--> 124\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    125\u001B[0m processed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfer(item, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams)\n\u001B[0;32m    126\u001B[0m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\pt_utils.py:266\u001B[0m, in \u001B[0;36mPipelinePackIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    263\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m accumulator\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_last:\n\u001B[1;32m--> 266\u001B[0m     processed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfer(\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterator), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams)\n\u001B[0;32m    267\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader_batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    268\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed, torch\u001B[38;5;241m.\u001B[39mTensor):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\base.py:1068\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[1;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[0;32m   1066\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[0;32m   1067\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m-> 1068\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[0;32m   1069\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1070\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:507\u001B[0m, in \u001B[0;36mAutomaticSpeechRecognitionPipeline._forward\u001B[1;34m(self, model_inputs, return_timestamps, generate_kwargs)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    505\u001B[0m     generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m encoder(inputs, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask)\n\u001B[1;32m--> 507\u001B[0m tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[0;32m    508\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[0;32m    509\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgenerate_kwargs,\n\u001B[0;32m    510\u001B[0m )\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_timestamps \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseq2seq_whisper\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    512\u001B[0m     out \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: tokens[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msequences\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_timestamps\u001B[39m\u001B[38;5;124m\"\u001B[39m: tokens[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_timestamps\u001B[39m\u001B[38;5;124m\"\u001B[39m]}\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:711\u001B[0m, in \u001B[0;36mWhisperGenerationMixin.generate\u001B[1;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, return_token_timestamps, return_segments, return_dict_in_generate, **kwargs)\u001B[0m\n\u001B[0;32m    708\u001B[0m         proc\u001B[38;5;241m.\u001B[39mset_begin_index(decoder_input_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    710\u001B[0m \u001B[38;5;66;03m# 6.8 Run generate with fallback\u001B[39;00m\n\u001B[1;32m--> 711\u001B[0m seek_sequences, seek_outputs, should_skip, do_condition_on_prev_tokens \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_with_fallback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    712\u001B[0m \u001B[43m    \u001B[49m\u001B[43msegment_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msegment_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_input_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    714\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcur_bsz\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcur_bsz\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    715\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_idx_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_idx_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseek\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseek\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    717\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_segment_frames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_segment_frames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    718\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_frames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_frames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    719\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemperatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    723\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprefix_allowed_tokens_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprefix_allowed_tokens_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    724\u001B[0m \u001B[43m    \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    725\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_token_timestamps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_timestamps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    726\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_condition_on_prev_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_condition_on_prev_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    727\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    728\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    730\u001B[0m \u001B[38;5;66;03m# 6.9 In every generated sequence, split by timestamp tokens and extract segments\u001B[39;00m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, seek_sequence \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(seek_sequences):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:797\u001B[0m, in \u001B[0;36mWhisperGenerationMixin.generate_with_fallback\u001B[1;34m(self, segment_input, decoder_input_ids, cur_bsz, batch_idx_map, seek, num_segment_frames, max_frames, temperatures, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_token_timestamps, do_condition_on_prev_tokens, kwargs)\u001B[0m\n\u001B[0;32m    794\u001B[0m generation_config\u001B[38;5;241m.\u001B[39mtemperature \u001B[38;5;241m=\u001B[39m temperature\n\u001B[0;32m    795\u001B[0m generation_config\u001B[38;5;241m.\u001B[39mnum_beams \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_beams\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m generation_config\u001B[38;5;241m.\u001B[39mdo_sample \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 797\u001B[0m seek_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[0;32m    798\u001B[0m     segment_input,\n\u001B[0;32m    799\u001B[0m     generation_config,\n\u001B[0;32m    800\u001B[0m     logits_processor,\n\u001B[0;32m    801\u001B[0m     stopping_criteria,\n\u001B[0;32m    802\u001B[0m     prefix_allowed_tokens_fn,\n\u001B[0;32m    803\u001B[0m     synced_gpus,\n\u001B[0;32m    804\u001B[0m     decoder_input_ids\u001B[38;5;241m=\u001B[39mdecoder_input_ids,\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    806\u001B[0m )\n\u001B[0;32m    808\u001B[0m \u001B[38;5;66;03m# post-process sequence tokens and outputs to be in list form\u001B[39;00m\n\u001B[0;32m    809\u001B[0m sequence_tokens, seek_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_postprocess_outputs(\n\u001B[0;32m    810\u001B[0m     seek_outputs, return_token_timestamps, generation_config\n\u001B[0;32m    811\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py:1479\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[0;32m   1462\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massisted_decoding(\n\u001B[0;32m   1463\u001B[0m         input_ids,\n\u001B[0;32m   1464\u001B[0m         candidate_generator\u001B[38;5;241m=\u001B[39mcandidate_generator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1475\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   1476\u001B[0m     )\n\u001B[0;32m   1477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mGREEDY_SEARCH:\n\u001B[0;32m   1478\u001B[0m     \u001B[38;5;66;03m# 11. run greedy search\u001B[39;00m\n\u001B[1;32m-> 1479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgreedy_search(\n\u001B[0;32m   1480\u001B[0m         input_ids,\n\u001B[0;32m   1481\u001B[0m         logits_processor\u001B[38;5;241m=\u001B[39mprepared_logits_processor,\n\u001B[0;32m   1482\u001B[0m         stopping_criteria\u001B[38;5;241m=\u001B[39mprepared_stopping_criteria,\n\u001B[0;32m   1483\u001B[0m         pad_token_id\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mpad_token_id,\n\u001B[0;32m   1484\u001B[0m         eos_token_id\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39meos_token_id,\n\u001B[0;32m   1485\u001B[0m         output_scores\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39moutput_scores,\n\u001B[0;32m   1486\u001B[0m         return_dict_in_generate\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mreturn_dict_in_generate,\n\u001B[0;32m   1487\u001B[0m         synced_gpus\u001B[38;5;241m=\u001B[39msynced_gpus,\n\u001B[0;32m   1488\u001B[0m         streamer\u001B[38;5;241m=\u001B[39mstreamer,\n\u001B[0;32m   1489\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[0;32m   1490\u001B[0m     )\n\u001B[0;32m   1492\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mCONTRASTIVE_SEARCH:\n\u001B[0;32m   1493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py:2353\u001B[0m, in \u001B[0;36mGenerationMixin.greedy_search\u001B[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[0;32m   2350\u001B[0m next_token_logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]\n\u001B[0;32m   2352\u001B[0m \u001B[38;5;66;03m# pre-process distribution\u001B[39;00m\n\u001B[1;32m-> 2353\u001B[0m next_tokens_scores \u001B[38;5;241m=\u001B[39m \u001B[43mlogits_processor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnext_token_logits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2355\u001B[0m \u001B[38;5;66;03m# Store scores, attentions and hidden_states when required\u001B[39;00m\n\u001B[0;32m   2356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_dict_in_generate:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\logits_process.py:97\u001B[0m, in \u001B[0;36mLogitsProcessorList.__call__\u001B[1;34m(self, input_ids, scores, **kwargs)\u001B[0m\n\u001B[0;32m     95\u001B[0m         scores \u001B[38;5;241m=\u001B[39m processor(input_ids, scores, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 97\u001B[0m         scores \u001B[38;5;241m=\u001B[39m \u001B[43mprocessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscores\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m scores\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:38:07.893628100Z",
     "start_time": "2025-03-23T17:58:04.902641Z"
    }
   },
   "cell_type": "code",
   "source": "result['chunks']",
   "id": "8726669e37b15c53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': (0.0, 5.04),\n",
       "  'text': ' This is a random forest, a powerful machine learning algorithm based on decision trees.'},\n",
       " {'timestamp': (0.0, 4.4),\n",
       "  'text': \" their backhands, their forehands, their heights, their ages, their dad's name, their mom's name,\"},\n",
       " {'timestamp': (0.0, 5.04),\n",
       "  'text': ' Grand Slam final of all time. I got it. Even this one time this kid bit Rafa Nadal and Novak'},\n",
       " {'timestamp': (0.0, 3.72),\n",
       "  'text': ' adventure book but instead of deciding whether you fight a dragon or run away'},\n",
       " {'timestamp': (0.0, 1.7), 'text': ' than 20 pounds for her ticket?'},\n",
       " {'timestamp': (0.0, 4.76),\n",
       "  'text': \" We don't need any fancy algorithm like with neural nets, no matrix multiplication, no\"},\n",
       " {'timestamp': (0.0, 3.76),\n",
       "  'text': ' First class passengers go one way and everyone else goes this way.'},\n",
       " {'timestamp': (0.0, 4.8),\n",
       "  'text': ' split dividing the data and checking purity until ta-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da-da- BOOM! Combine the datasets, remove empty data, get the ranking difference between winner'},\n",
       " {'timestamp': (0.0, 5.1),\n",
       "  'text': \" last 50 matches and a bunch of other stats that I won't get into.\"},\n",
       " {'timestamp': (0.0, 2.0), 'text': ' to this one, player elo.'},\n",
       " {'timestamp': (0.0, 4.24),\n",
       "  'text': \" Now here's his elo progression plotted against every tennis player ever.\"},\n",
       " {'timestamp': (0.0, 4.88),\n",
       "  'text': ' In a shocking comeback Alcaraz won the match, which by the way I watched live and it was really cool.'},\n",
       " {'timestamp': (0.0, 2.56),\n",
       "  'text': \" And here's how their elo has evolved over time.\"},\n",
       " {'timestamp': (0.0, 7.28),\n",
       "  'text': \" The guy is a beast and as you can see his clay elo is really really good. In fact, it's the highest I've seen.\"},\n",
       " {'timestamp': (0.0, 4.08),\n",
       "  'text': ' And while my model is training, I want to thank Brilliant for sponsoring this video.'},\n",
       " {'timestamp': (0.0, 5.44),\n",
       "  'text': ' on data analysis and probability where you learn by experimenting with hands-on examples.'},\n",
       " {'timestamp': (0.0, 6.4),\n",
       "  'text': ' my code green code for a 30 day free trial and a 20% discount on the annual premium subscription.'},\n",
       " {'timestamp': (0.0, 6.56),\n",
       "  'text': \" it on smaller datasets and it works just as fine, it's not ready to handle 95,000 tennis matches.\"},\n",
       " {'timestamp': (0.0, 1.96), 'text': \" specific data it's trained on.\"},\n",
       " {'timestamp': (0.0, 4.48),\n",
       "  'text': \" way there's a little bit of more variation which makes the model more robust.\"},\n",
       " {'timestamp': (0.0, 6.68),\n",
       "  'text': ' the random forest parameters, but no matter what I tried, I got stuck at 76-77% accuracy.'},\n",
       " {'timestamp': (0.0, 4.76),\n",
       "  'text': ' But anyway, I got a staggering 85% accuracy baby!'},\n",
       " {'timestamp': (0.0, 6.0),\n",
       "  'text': \" You see, I trained my models with tennis matches up until December 2024, so this year's Australian\"},\n",
       " {'timestamp': (0.0, 1.0), 'text': ' his matches.'},\n",
       " {'timestamp': (1.0, 4.56),\n",
       "  'text': ' So my model correctly predicted the winner of a grand slam.'},\n",
       " {'timestamp': (1.7, 3.82), 'text': ' Yes she did, so we go left.'},\n",
       " {'timestamp': (1.96, 6.6),\n",
       "  'text': \" But if we create multiple trees, it's making its own prediction, we can combine the results\"},\n",
       " {'timestamp': (2.0, 4.96),\n",
       "  'text': ' Cause it seems to be splitting data really well.'},\n",
       " {'timestamp': (2.56, 8.4),\n",
       "  'text': \" This represents their overall elo, but in tennis, the surface you're playing with really matters.\"},\n",
       " {'timestamp': (3.72, 8.44),\n",
       "  'text': \" it's deciding who won a tennis match. Let's take the Titanic disaster as an\"},\n",
       " {'timestamp': (3.76, 6.2),\n",
       "  'text': \" But hold up, there's still some impurity.\"},\n",
       " {'timestamp': (3.82, 5.72),\n",
       "  'text': ' Next question, was she in first class?'},\n",
       " {'timestamp': (4.08, 8.72),\n",
       "  'text': ' Brilliant is an online learning platform for computer science, science, and maths.'},\n",
       " {'timestamp': (4.24, 6.12), 'text': ' As you can see, he is way up there.'},\n",
       " {'timestamp': (4.4, 9.44),\n",
       "  'text': \" their grandma's secret lasagna recipe. Yeah, I need that stuff too man, I'm surviving on noodles\"},\n",
       " {'timestamp': (4.48, 8.88),\n",
       "  'text': ' I also implemented my own random forest from scratch but guess what it was too slow for'},\n",
       " {'timestamp': (4.56, 6.3), 'text': ' Which is pretty sick if you ask me.'},\n",
       " {'timestamp': (4.76, 10.08),\n",
       "  'text': ' gradient descent, none of that fancy crap, just some logic and some simple arithmetic.'},\n",
       " {'timestamp': (4.76, 9.64),\n",
       "  'text': ' And as you can see, the most important features it recognized were Elo surface difference'},\n",
       " {'timestamp': (4.8, 7.56), 'text': ' and loser, do this bullsh**, ok?'},\n",
       " {'timestamp': (4.88, 10.64),\n",
       "  'text': ' And since he won his rating has to be updated so we take this handy little formula and calculate'},\n",
       " {'timestamp': (4.96, 7.52),\n",
       "  'text': ' So let me show you how I calculated this.'},\n",
       " {'timestamp': (5.04, 8.32),\n",
       "  'text': \" And this is tennis, a sport I'm kind of obsessed with.\"},\n",
       " {'timestamp': (5.04, 10.16),\n",
       "  'text': ' Djokovic back to back. I have it. I have it all. I have every single ATP, Association of Tennis'},\n",
       " {'timestamp': (5.1, 9.64),\n",
       "  'text': ' But before we throw all this stuff to our classifier, we need to plot our data.'},\n",
       " {'timestamp': (5.44, 10.56),\n",
       "  'text': ' They make learning fun by giving you puzzles and little games to test your understanding.'},\n",
       " {'timestamp': (5.72, 6.72), 'text': ' Yes again.'},\n",
       " {'timestamp': (6.0, 8.04), 'text': ' Open was not in my dataset.'},\n",
       " {'timestamp': (6.12, 10.22),\n",
       "  'text': \" And if you're wondering about these two other lines, naturally those are Rafa Nadal and\"},\n",
       " {'timestamp': (6.2, 8.7), 'text': ' Not everyone in first class survived.'},\n",
       " {'timestamp': (6.3, 8.2), 'text': ' I had a lot of fun with this video.'},\n",
       " {'timestamp': (6.4, 11.6),\n",
       "  'text': \" Seriously, they're awesome. So go check them out. Oh, okay. Our decision tree finished training and\"},\n",
       " {'timestamp': (6.56, 12.8),\n",
       "  'text': ' But anyway, using that classifier out of the box, we get 74% accuracy, which sounds really'},\n",
       " {'timestamp': (6.6, 10.16),\n",
       "  'text': ' through a majority vote and get a more stable and accurate model.'},\n",
       " {'timestamp': (6.68, 10.0), 'text': ' So I decided to try XGBoost.'},\n",
       " {'timestamp': (6.72, 11.04),\n",
       "  'text': ' At this point, our tree confidently predicts that she survived, because well, she actually'},\n",
       " {'timestamp': (7.28, 16.48),\n",
       "  'text': \" As a final example, here's how Carlos Alcaraz, Gras's elo has changed after winning back to back Wimbledon titles in 2023 and 2024.\"},\n",
       " {'timestamp': (7.52, 11.56),\n",
       "  'text': \" The elo rating system is a way to approximate a player's skill level.\"},\n",
       " {'timestamp': (7.56, 8.68), 'text': ' But the beam but the boom?'},\n",
       " {'timestamp': (8.04, 14.9),\n",
       "  'text': ' And out of the 116 matches I could find, my model correctly predicted 99 of them and got'},\n",
       " {'timestamp': (8.2, 13.66),\n",
       "  'text': ' So if you want me to try to predict this years Wimbledon champion using XG boost from scratch,'},\n",
       " {'timestamp': (8.32, 12.72),\n",
       "  'text': \" In this video, I'll build a random forest, throw at it a bunch of tennis data,\"},\n",
       " {'timestamp': (8.4, 12.56),\n",
       "  'text': \" It's really different playing tennis in clay, grass or hard surfaces,\"},\n",
       " {'timestamp': (8.44, 12.6),\n",
       "  'text': \" example. We've got a lot of data on passengers things like their age, their\"},\n",
       " {'timestamp': (8.68, 10.76), 'text': ' My beautiful dataset is complete.'},\n",
       " {'timestamp': (8.7, 9.7), 'text': ' So what now?'},\n",
       " {'timestamp': (8.72, 14.88),\n",
       "  'text': ' They have great courses on everything from calculus and linear algebra all the way up to neural networks.'},\n",
       " {'timestamp': (8.88, 10.76), 'text': ' my huge data set again.'},\n",
       " {'timestamp': (9.44, 15.76),\n",
       "  'text': ' over here. And then I found it, the holy grail of tennis datasets. A file so massive, so detailed,'},\n",
       " {'timestamp': (9.64, 10.84), 'text': ' Plot plot plot plot.'},\n",
       " {'timestamp': (9.64, 12.16), 'text': ' and total elo, which is pretty cool.'},\n",
       " {'timestamp': (9.7, 11.94), 'text': ' Well we look for the next best split.'},\n",
       " {'timestamp': (10.0, 14.28),\n",
       "  'text': ' An XGBoost classifier is like a random forest on steroids.'},\n",
       " {'timestamp': (10.08, 11.48), 'text': \" Here's how this works.\"},\n",
       " {'timestamp': (10.16, 16.24),\n",
       "  'text': ' Professionals, match from 1981 to 2024 baby. But before using this data, I want to try building a'},\n",
       " {'timestamp': (10.16, 13.08),\n",
       "  'text': ' Now building a decision tree is deterministic.'},\n",
       " {'timestamp': (10.22, 12.72),\n",
       "  'text': ' Nobac Djokovic, two other tennis legends.'},\n",
       " {'timestamp': (10.56, 15.12),\n",
       "  'text': ' They even have courses on search engines, cryptocurrencies, quantum computing,'},\n",
       " {'timestamp': (10.64, 16.96),\n",
       "  'text': ' his new rating. Turns out Alcaraz gained about 14 points and Djokovic lost about 14 points so'},\n",
       " {'timestamp': (10.76, 15.2),\n",
       "  'text': ' It has 95,000 tennis matches with their corresponding statistics.'},\n",
       " {'timestamp': (10.76, 14.2), 'text': ' But using sklearn I got 76%.'},\n",
       " {'timestamp': (10.84, 15.32),\n",
       "  'text': ' So I cooked up a quick SNS spare plot and MWAH I got this beauty.'},\n",
       " {'timestamp': (11.04, 12.04), 'text': ' did.'},\n",
       " {'timestamp': (11.48, 14.6),\n",
       "  'text': ' First we grab all the titanic data and start with an empty tree.'},\n",
       " {'timestamp': (11.56, 16.16),\n",
       "  'text': \" It's mostly commonly used in chess, but I decided to apply it to my tennis dataset.\"},\n",
       " {'timestamp': (11.6, 16.48),\n",
       "  'text': ' I have some good news and some bad news. Good news is that it gave us a pretty cool looking'},\n",
       " {'timestamp': (11.94, 12.94), 'text': ' And guess what?'},\n",
       " {'timestamp': (12.04, 15.34),\n",
       "  'text': ' And we can use this tree again and again to predict other passengers.'},\n",
       " {'timestamp': (12.16, 16.34),\n",
       "  'text': ' Just for fun, I also decided to quickly train a neural net to see how it would do on this'},\n",
       " {'timestamp': (12.56, 16.08),\n",
       "  'text': ' so I also implemented surface-specific elo.'},\n",
       " {'timestamp': (12.6, 17.52),\n",
       "  'text': ' cabin and ticket class. A decision tree works by asking a series of yes and no'},\n",
       " {'timestamp': (12.72, 17.76),\n",
       "  'text': ' and then make it predict tennis match outcomes and predict the winner of a big tennis tournament.'},\n",
       " {'timestamp': (12.72, 15.84),\n",
       "  'text': ' And the cool thing is that elo is fairly easy to code.'},\n",
       " {'timestamp': (12.8, 19.68),\n",
       "  'text': ' promising until you realize that simply predicting based on elo alone gives you 72% accuracy.'},\n",
       " {'timestamp': (12.94, 14.94), 'text': ' The strongest predictor now is sex.'},\n",
       " {'timestamp': (13.08, 18.22),\n",
       "  'text': \" That is, if the input stays the same, we'll build exactly the same tree over and over.\"},\n",
       " {'timestamp': (13.66, 15.56),\n",
       "  'text': ' like the video and comment potato below.'},\n",
       " {'timestamp': (14.2, 15.2), 'text': ' Not bad.'},\n",
       " {'timestamp': (14.28, 19.24),\n",
       "  'text': ' It uses boosting, regularization to prevent overfitting, and it keeps trees from growing'},\n",
       " {'timestamp': (14.6, 19.72),\n",
       "  'text': ' Now our goal is to find the variable that best splits the passengers into survivors'},\n",
       " {'timestamp': (14.88, 18.72),\n",
       "  'text': \" In fact, I have done a lot of stuff behind the scenes that I haven't really shown in the video,\"},\n",
       " {'timestamp': (14.9, 21.44),\n",
       "  'text': \" only 17 wrong and hence has an accuracy of 85% on this year's Australian Open.\"},\n",
       " {'timestamp': (14.94, 17.8), 'text': ' So we slice the data again and boom!'},\n",
       " {'timestamp': (15.12, 21.12),\n",
       "  'text': ' how AI works and loads and loads of other fascinating things. So if you want to support'},\n",
       " {'timestamp': (15.2, 18.48),\n",
       "  'text': \" And there's a lot of statistics I calculated.\"},\n",
       " {'timestamp': (15.2, 19.08),\n",
       "  'text': ' We can even visualize our forest and it looks like this.'},\n",
       " {'timestamp': (15.32, 20.36),\n",
       "  'text': ' A bunch of variables plotted against each other showing us some interesting patterns.'},\n",
       " {'timestamp': (15.34, 20.98),\n",
       "  'text': ' This is really a simple tree, but this is what I got when training with a titanic dataset.'},\n",
       " {'timestamp': (15.56, 19.04),\n",
       "  'text': \" If 50 people comment potato, I guess I'll make a second part.\"},\n",
       " {'timestamp': (15.76, 22.08),\n",
       "  'text': ' that opening it, crashed my computer, summoned three statisticians, and made my ex-el beg for mercy.'},\n",
       " {'timestamp': (15.84, 20.48),\n",
       "  'text': \" Let's take the 2023 Wimbledon final between Carlos Alcaraz and Nobac Djokovic.\"},\n",
       " {'timestamp': (16.08, 19.12),\n",
       "  'text': ' For example, Draphanoval is known as the king of clay.'},\n",
       " {'timestamp': (16.16, 18.12),\n",
       "  'text': \" Let's take Roger Featherer as an example.\"},\n",
       " {'timestamp': (16.24, 21.2),\n",
       "  'text': \" decision tree from scratch. That's right. No skleler, no pie torch, just my good old friend\"},\n",
       " {'timestamp': (16.34, 19.92),\n",
       "  'text': ' data and I got a decent 83% accuracy.'},\n",
       " {'timestamp': (16.48, 20.48),\n",
       "  'text': ' And Tennis elo turns out to be quite good at predicting who will win.'},\n",
       " {'timestamp': (16.48, 23.2),\n",
       "  'text': ' decision tree. Bad news is that my implementation was really slow, like painfully slow. So I ended'},\n",
       " {'timestamp': (16.96, 22.0),\n",
       "  'text': \" it's pretty easy. Actually according to my tennis elo rankings the current best player in the world\"},\n",
       " {'timestamp': (17.52, 21.94),\n",
       "  'text': \" questions to classify whether someone survived. For example let's take miss\"},\n",
       " {'timestamp': (17.76, 19.44), 'text': \" And we'll see how it performs.\"},\n",
       " {'timestamp': (17.8, 20.1), 'text': ' Every female in first class survived.'},\n",
       " {'timestamp': (18.12, 22.12),\n",
       "  'text': ' At the start of his career, his elo rating was around 1500.'},\n",
       " {'timestamp': (18.22, 23.74),\n",
       "  'text': ' So the trick to build a random forest is build many trees using different random subsets'},\n",
       " {'timestamp': (18.48, 22.6),\n",
       "  'text': ' For example, the head to head for every match, that is, the number of times a player has'},\n",
       " {'timestamp': (18.72, 22.48),\n",
       "  'text': ' like principal component analysis, linear regression, and a bunch more.'},\n",
       " {'timestamp': (19.04, 21.68),\n",
       "  'text': \" Hope you enjoyed it and I'll see you in the next one.\"},\n",
       " {'timestamp': (19.08, 20.08), 'text': ' Pretty sick right?'},\n",
       " {'timestamp': (19.12, 25.2),\n",
       "  'text': \" He's won 14 french opens and has a 112 win vs 4 losses record at the event.\"},\n",
       " {'timestamp': (19.24, 20.24), 'text': ' too large.'},\n",
       " {'timestamp': (19.44, 21.2), 'text': ' But first, I need data.'},\n",
       " {'timestamp': (19.68, 20.8), 'text': ' So yeah, we can do better.'},\n",
       " {'timestamp': (19.72, 21.22), 'text': ' and non-survivors.'},\n",
       " {'timestamp': (19.92, 24.32),\n",
       "  'text': ' Now to end this video, I wanted to see if my model could predict the winner of this'},\n",
       " {'timestamp': (20.08, 22.0), 'text': ' Now at this point things got tricky.'},\n",
       " {'timestamp': (20.1, 23.98),\n",
       "  'text': ' That means we have hit a pure note, which we marked as survived.'},\n",
       " {'timestamp': (20.24, 23.72),\n",
       "  'text': \" It's kinda hard to explain in this video, but maybe if you liked the video, I could\"},\n",
       " {'timestamp': (20.36, 25.54),\n",
       "  'text': ' Of course some variables are absolutely useless, like player ID, but I want to draw your attention'},\n",
       " {'timestamp': (20.48, 27.12),\n",
       "  'text': ' Alcaraz was rated about 2063 and Djokovic was rated about 2120, according of course'},\n",
       " {'timestamp': (20.48, 27.04),\n",
       "  'text': \" So let's take all this data and fit it into a decision tree to see how well it classifies winners.\"},\n",
       " {'timestamp': (20.8, 24.0),\n",
       "  'text': ' To take things to the next level, we need random forests.'},\n",
       " {'timestamp': (20.98, 24.22),\n",
       "  'text': ' And you might be asking, how do we build this huge tree?'},\n",
       " {'timestamp': (21.12, 26.48),\n",
       "  'text': ' this channel and explore exciting and interesting topics, click the link in the description and use'},\n",
       " {'timestamp': (21.2, 22.8), 'text': ' I want a lot of data.'},\n",
       " {'timestamp': (21.2, 26.48),\n",
       "  'text': ' Nampa and me. And decision trees are pretty awesome. Think of them like a chose your own'},\n",
       " {'timestamp': (21.22, 25.32),\n",
       "  'text': ' Turns out that the most powerful first split is passenger class.'},\n",
       " {'timestamp': (21.44, 26.2),\n",
       "  'text': ' More importantly, it correctly predicted that Janik Sinner would win every single one of'},\n",
       " {'timestamp': (21.94, 27.08),\n",
       "  'text': ' Elizabeth Bonnell. A simple decision tree might start by asking did she pay more'},\n",
       " {'timestamp': (22.0, 27.36),\n",
       "  'text': ' is Janek Sinner who just won the Australian Open followed by Novak Djokovic and Carlos Alcaraz.'},\n",
       " {'timestamp': (22.0, 26.36),\n",
       "  'text': ' I tried to improve my model by running a grid search, tweaking the data and fine tuning'},\n",
       " {'timestamp': (22.08, 28.08),\n",
       "  'text': ' The famous 2008 Wimbledon final between Rafa Nadal and Roger Federer. I got it. The longest'},\n",
       " {'timestamp': (22.12, 23.12), 'text': ' Pretty average.'},\n",
       " {'timestamp': (22.48, 27.6),\n",
       "  'text': \" And while I won't have time to explain it, Brilliant has some fantastic introductory courses\"},\n",
       " {'timestamp': (22.6, 25.02), 'text': ' won or lost against another player.'},\n",
       " {'timestamp': (22.8, 26.4),\n",
       "  'text': ' I want every single breakpoint, every single double surf, every single double fold.'},\n",
       " {'timestamp': (23.12, 27.8),\n",
       "  'text': ' But as he kept winning matches, his rating skyrocketed, eventually becoming one of the'},\n",
       " {'timestamp': (23.2, 28.8),\n",
       "  'text': ' up having to use SKLearns version, but for all the haters out there, my code works. Okay. I tested'},\n",
       " {'timestamp': (23.72, 25.2), 'text': ' explain it in another one.'},\n",
       " {'timestamp': (23.74, 26.98),\n",
       "  'text': ' of the data and different subsets of the variables.'},\n",
       " {'timestamp': (23.98, 28.08),\n",
       "  'text': ' And for the other branches of the tree, we keep repeating this process, finding the best'},\n",
       " {'timestamp': (24.0, 28.4),\n",
       "  'text': \" A single decision tree tends to have high variance, so it's quite sensitive to the\"},\n",
       " {'timestamp': (24.22, 25.9), 'text': ' Well, this is the coolest part.'},\n",
       " {'timestamp': (24.32, 25.88), 'text': \" year's Australian Open.\"},\n",
       " {'timestamp': (25.02, 29.56),\n",
       "  'text': \" The player's age difference, their height difference, the number of matches won in the\"},\n",
       " {'timestamp': (25.2, 26.84), 'text': ' But you know, up to you.'},\n",
       " {'timestamp': (25.32, 26.72), 'text': ' Alright so we split the data.'},\n",
       " {'timestamp': (26.4, 27.44), 'text': ' I want everything.'},\n",
       " {'timestamp': (26.84, 28.44), 'text': \" It's right there though.\"},\n",
       " {'timestamp': (27.12, 28.12), 'text': ' to my calculations.'},\n",
       " {'timestamp': (27.8, 29.64), 'text': ' greatest players of all time.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:38:07.896628600Z",
     "start_time": "2025-03-23T19:47:07.293450Z"
    }
   },
   "cell_type": "code",
   "source": "text",
   "id": "eb36c0b56b07a712",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(0.0, 5.04), Tekst:  This is a random forest, a powerful machine learning algorithm based on decision trees.\\n(0.0, 7.76), Tekst:  I want everything their backhands their forehands their heights their ages their dad's name their mom's name their grandma's secret lasagna recipe\\n(0.0, 2.54), Tekst:  I got it the longest Grand Slam final of all time\\n(0.0, 1.0), Tekst:  awesome.\\n(0.0, 5.68), Tekst:  A simple decision tree might start by asking did she pay more than 20 pounds for her ticket?\\n(0.0, 4.74), Tekst:  We don't need any fancy algorithm like with neural nets, no matrix multiplication, no\\n(0.0, 1.0), Tekst:  this way.\\n(0.0, 5.76), Tekst:  until, ta-ta-dun, we have ourselves a fully grown, absolutely magnificent decision tree.\\n(0.0, 5.12), Tekst:  data sets, remove empty data, get the ranking difference between winner and loser, do this\\n(0.0, 5.36), Tekst:  number of matches won in the last 50 matches and a bunch of other stats that I won't get into.\\n(0.0, 4.96), Tekst:  to this one, player elo, cause it seems to be splitting data really well.\\n(0.0, 4.16), Tekst:  Now here's his elo progression plotted against every tennis player ever.\\n(0.0, 7.4), Tekst:  In a shocking comeback, Alcaraz won the match, and since he won, his rating has to be updated,\\n(0.0, 2.62), Tekst:  And here's how their elo has evolved over time.\\n(0.0, 5.52), Tekst:  The guy is a beast, and as you can see his clay elo is really really good, in fact it's\\n(0.0, 3.96), Tekst:  While my model is training, I want to thank Brilliant for sponsoring this video.\\n(0.0, 6.08), Tekst:  courses on data analysis and probability where you learn by experimenting with hands-on examples.\\n(0.0, 5.76), Tekst:  click the link in the description and use my code greencode for a 30 day free trial and a 20%\\n(0.0, 4.72), Tekst:  version but for all the haters out there my code works okay I tested it on smaller data\\n(0.0, 5.28), Tekst:  To take things to the next level, we need random forests. A single decision tree tends to have\\n(0.0, 5.76), Tekst:  So the trick to build a random forest is build many trees using different random subsets\\n(0.0, 4.76), Tekst:  Now at this point things got tricky, I tried to improve my model by running a grid search,\\n(0.0, 4.0), Tekst:  It's kinda hard to explain in this video, but maybe if you liked the video I could explain\\n(0.0, 4.38), Tekst:  Now to end this video, I wanted to see if my model could predict the winner of this\\n(0.0, 4.76), Tekst:  More importantly, it correctly predicted that Jannik Sinner would win every single one of\\n(1.0, 5.16), Tekst:  Think of them like a chose your own adventure book but instead of deciding whether you fight\\n(1.0, 5.68), Tekst:  But hold up, there is still some impurity, not everyone in first class survived.\\n(2.54, 8.0), Tekst:  I got it even this one time this kid bit Rafa Nadal and Novak Djokovic back to back. I have it\\n(2.62, 7.48), Tekst:  This represents their overall elo, but in tennis, the surface you are playing with really\\n(3.96, 8.28), Tekst:  Brilliant is an online learning platform for computer science, science and maths.\\n(4.0, 8.42), Tekst:  it in another one, but you know, up to you, it's right there though, just saying.\\n(4.16, 6.04), Tekst:  As you can see he is way up there.\\n(4.38, 5.96), Tekst:  year's Australian Open.\\n(4.72, 11.36), Tekst:  sets and it works just as fine it just it's not ready to handle 95 000 tennis matches but anyway\\n(4.74, 10.06), Tekst:  gradient descent, none of that fancy crap, just some logic and some simple arithmetic.\\n(4.76, 9.4), Tekst:  tweaking the data and fine tuning the random forest parameters, but no matter what I tried\\n(4.76, 5.76), Tekst:  his matches.\\n(4.96, 7.5), Tekst:  So let me show you how I calculated this.\\n(5.04, 8.32), Tekst:  And this is tennis, a sport I'm kind of obsessed with.\\n(5.12, 9.52), Tekst:  bullshit, ok, by the beam by the boom, my beautiful data set is complete.\\n(5.16, 9.0), Tekst:  a dragon or run away, it's deciding who won a tennis match.\\n(5.28, 10.32), Tekst:  high variance, so it's quite sensitive to the specific data it's trained on. But if we create\\n(5.52, 7.4), Tekst:  the highest I've seen.\\n(5.68, 7.6), Tekst:  Yes she did, so we go left.\\n(5.68, 6.68), Tekst:  So what now?\\n(5.76, 6.92), Tekst:  Woo, let's go!\\n(5.76, 10.64), Tekst:  discount on the annual premium subscription. Seriously, they're awesome, so go check them out.\\n(5.76, 9.0), Tekst:  of the data and different subsets of the variables.\\n(5.76, 10.52), Tekst:  So my model correctly predicted the winner of a grand slam, which is pretty sick if you\\n(5.96, 11.96), Tekst:  You see, I trained my models with tennis matches up until December 2024, so this year's Australian\\n(6.04, 9.96), Tekst:  And if you're wondering about these two other lines, naturally those are Rafa Nadal\\n(6.08, 11.2), Tekst:  They make learning fun by giving you puzzles and little games to test your understanding.\\n(6.4, 10.88), Tekst:  But before we throw all this stuff to our classifier, we need to plot our data.\\n(6.68, 8.92), Tekst:  Well we look for the next best split.\\n(6.92, 11.12), Tekst:  Implementing this in Python was actually pretty straightforward, but I don't think it's gonna\\n(7.4, 11.86), Tekst:  so we take this handy little formula and calculate his new rating.\\n(7.4, 12.72), Tekst:  As a final example, here's how Carlos Alcaraz Gras's elo has changed after winning back\\n(7.48, 8.48), Tekst:  matters.\\n(7.5, 11.56), Tekst:  The elo rating system is a way to approximate a player's skill level.\\n(7.6, 9.5), Tekst:  Next question, was she in first class?\\n(7.76, 9.4), Tekst:  Yeah, I need that stuff too, man\\n(8.0, 14.7), Tekst:  I have it all I have every single ATP Association of tennis professionals match from 1981 to 2024, baby\\n(8.28, 12.88), Tekst:  They have great courses on everything from calculus and linear algebra all the way up\\n(8.32, 13.12), Tekst:  In this video, I'll build a random forest, throw at it a bunch of tennis data and then\\n(8.42, 13.14), Tekst:  But anyway, I got a staggering 85% accuracy baby, yoo hoo!\\n(8.48, 14.2), Tekst:  It's really different playing tennis in clay, grass or hard surfaces, so I also implemented\\n(8.92, 11.92), Tekst:  And guess what, the strongest predictor now is sex.\\n(9.0, 11.6), Tekst:  Let's take the titanic disaster as an example.\\n(9.0, 13.5), Tekst:  This way there's a little bit of more variation which makes the model more robust.\\n(9.4, 15.9), Tekst:  I'm surviving on noodles over here and then I found it the holy grail of tennis datasets a file so massive\\n(9.4, 16.24), Tekst:  I got stuck at 76-77% accuracy, so I decided to try XGBoost.\\n(9.5, 14.44), Tekst:  Yes again, at this point our tree confidently predicts that she survived, because well she\\n(9.52, 14.32), Tekst:  It has 95 thousand tennis matches with their corresponding statistics, and there's a\\n(9.96, 12.64), Tekst:  and Novak Djokovic, two other tennis legends.\\n(10.06, 11.48), Tekst:  Here's how this works.\\n(10.32, 14.88), Tekst:  multiple trees, it's making its own prediction, we can combine the results through a majority\\n(10.52, 11.52), Tekst:  ask me.\\n(10.64, 15.76), Tekst:  Oh, okay, our decision tree finished training and I have some good news and some bad news.\\n(10.88, 16.8), Tekst:  Plot plot plot plot. So I cooked up a quick SNS pair plot and mwah, I got this beauty.\\n(11.12, 12.68), Tekst:  be very fast.\\n(11.2, 15.76), Tekst:  They even have courses on search engines, cryptocurrencies, quantum computing,\\n(11.36, 18.0), Tekst:  using that classifier out of the box we get 74 accuracy which sounds really promising until you\\n(11.48, 14.6), Tekst:  First we grab all the titanic data and start with an empty tree.\\n(11.52, 15.18), Tekst:  I had a lot of fun with this video, so if you want me to try to predict this year's\\n(11.56, 16.16), Tekst:  It's mostly commonly used in chess, but I decided to apply it to my tennis dataset.\\n(11.6, 16.72), Tekst:  We've got a lot of data on passengers, things like their age, their cabin and ticket class.\\n(11.86, 17.28), Tekst:  Turns out Alcaraz gained about 14 points and Djokovic lost about 14 points, so it's pretty\\n(11.92, 17.08), Tekst:  So we slice the date again and boom, every female in first class survived.\\n(11.96, 14.0), Tekst:  Open was not in my dataset.\\n(12.64, 15.48), Tekst:  And the cool thing is that elo is fairly easy to code.\\n(12.68, 18.76), Tekst:  Great, so now we have a fully working decision tree classifier, but before we use it to predict\\n(12.72, 16.58), Tekst:  to back Wimbledon titles in 2023 and 2024.\\n(12.88, 14.4), Tekst:  to neural networks.\\n(13.12, 17.76), Tekst:  make it predict tennis match outcomes and predict the winner of a big tennis tournament.\\n(13.14, 18.04), Tekst:  And as you can see, the most important features it recognized were Elo surface difference\\n(13.5, 17.88), Tekst:  I also implemented my own random forest from scratch, but guess what, it was too slow for\\n(14.0, 20.86), Tekst:  And out of the 116 matches I could find, my model correctly predicted 99 of them and got\\n(14.2, 16.04), Tekst:  surface specific elo.\\n(14.32, 17.28), Tekst:  lot of statistics I calculated, let me tell you that.\\n(14.4, 17.6), Tekst:  In fact, I have done a lot of stuff behind the scenes that I haven't really shown in\\n(14.44, 15.52), Tekst:  actually did.\\n(14.6, 19.62), Tekst:  Now our goal is to find the variable that best splits the passengers into survivors\\n(14.7, 19.22), Tekst:  But before using this data, I want to try building a decision tree from scratch. That's right\\n(14.88, 20.4), Tekst:  vote and get a more stable and accurate model. Now building a decision tree is deterministic,\\n(15.18, 20.32), Tekst:  Wimbledon champion using XG boost from scratch, like the video and comment potato below.\\n(15.48, 20.36), Tekst:  Let's take the 2023 Wimbledon final between Carlos Alcaraz and Novak Djokovic.\\n(15.52, 19.12), Tekst:  And we can use this tree again and again to predict other passengers.\\n(15.76, 20.24), Tekst:  how AI works and loads and loads of other fascinating things.\\n(15.76, 20.72), Tekst:  Good news is that it gave us a pretty cool looking decision tree. Bad news is that my\\n(15.9, 18.26), Tekst:  So detailed that opening it crushed my computer\\n(16.04, 19.1), Tekst:  For example, Draphene Valle is known as the king of clay.\\n(16.16, 18.44), Tekst:  Let's take Roger Federer as an example.\\n(16.24, 22.32), Tekst:  An XGBoost classifier is like a random forest on steroids, it uses boosting, regularization\\n(16.58, 20.5), Tekst:  And tennis elo turns out to be quite good at predicting who will win.\\n(16.72, 22.12), Tekst:  A decision tree works by asking a series of yes and no questions to classify whether someone\\n(16.8, 21.76), Tekst:  A bunch of variables plotted against each other, showing us some interesting patterns.\\n(17.08, 20.96), Tekst:  That means we have hit a pure node, which we marked as survived.\\n(17.28, 21.38), Tekst:  For example, the head to head for every match, that is, the number of times a player has\\n(17.28, 18.28), Tekst:  easy.\\n(17.6, 22.16), Tekst:  the video like principal component analysis, linear regression and a bunch more.\\n(17.76, 19.44), Tekst:  And we'll see how it performs.\\n(17.88, 23.2), Tekst:  my huge dataset again, but using SKlearn I got 76%.\\n(18.0, 24.64), Tekst:  realize that simply predicting based on elo alone gives you 72 accuracy so yeah we can do better.\\n(18.04, 20.58), Tekst:  and total elo, which is pretty cool.\\n(18.28, 22.48), Tekst:  Actually, according to my tennis elo rankings, the current best player in the world is Janek\\n(18.44, 23.56), Tekst:  At the start of his career, his elo rating was around 1500, pretty average, but as he\\n(18.76, 23.76), Tekst:  Summoned three statisticians and made my ex all beg for mercy the famous\\n(18.76, 23.44), Tekst:  the outcome of the tennis matches and gamble some money, we need to clean up the tennis\\n(19.1, 25.12), Tekst:  He's won 14 french opens and has a 112 win vs 4 losses record at the event.\\n(19.12, 23.96), Tekst:  This is really a simple tree, but this is what I got when training with the Titanic\\n(19.22, 25.12), Tekst:  No SK learner, Pytorch, just my good old friend Nampa and me and decision trees are pretty awesome\\n(19.44, 22.8), Tekst:  But first, I need data. I want a lot of data.\\n(19.62, 21.24), Tekst:  and non-survivors.\\n(20.24, 25.2), Tekst:  So if you want to support this channel and explore exciting and interesting topics,\\n(20.32, 23.8), Tekst:  If 50 people comment potato, I guess I'll make a second part.\\n(20.36, 27.18), Tekst:  Alcaraz was rated about 2063 and Djokovic was rated about 2120 according of course to\\n(20.4, 25.52), Tekst:  that is, if the input stays the same, we'll build exactly the same tree over and over.\\n(20.5, 26.5), Tekst:  So let's take all this data and fit it into a decision tree to see how well it classifies\\n(20.58, 24.76), Tekst:  Just for fun, I also decided to quickly train a neural net to see how it would do on this\\n(20.72, 26.88), Tekst:  implementation was really slow, like painfully slow, so I ended up having to use SKlearn's\\n(20.86, 27.4), Tekst:  only 17 wrong and hence has an accuracy of 85% on this year's Australian Open.\\n(20.96, 25.08), Tekst:  And for the other branches of the tree, we keep repeating this process, finding the best\\n(21.24, 25.32), Tekst:  Turns out that the most powerful first split is passenger class.\\n(21.38, 26.8), Tekst:  won or lost against another player, the player's age difference, their height difference, the\\n(21.76, 27.12), Tekst:  Of course some variables are absolutely useless, like player ID, but I wanna draw your attention\\n(22.12, 23.12), Tekst:  survived.\\n(22.16, 26.36), Tekst:  And while I won't have time to explain it, Brilliant has some fantastic introductory\\n(22.32, 26.28), Tekst:  to prevent overfitting and it keeps trees from growing too large.\\n(22.48, 27.44), Tekst:  Sinner, who just won the Australian Open, followed by Novak Djokovic and Carlos Agaraf.\\n(22.8, 26.4), Tekst:  I want every single breakpoint, every single double serve, every single double fold.\\n(23.12, 25.76), Tekst:  For example, let's take Ms Elizabeth Bonnell.\\n(23.2, 24.2), Tekst:  Not bad, not bad.\\n(23.44, 25.64), Tekst:  data, cause it's looking kind of gross.\\n(23.56, 28.7), Tekst:  kept winning matches, his rating skyrocketed, eventually becoming one of the greatest players\\n(23.8, 26.4), Tekst:  Hope you enjoyed it and I'll see you in the next one.\\n(23.96, 24.96), Tekst:  dataset.\\n(24.12, 28.0), Tekst:  2008 Wimbledon final between Rafa Nadal and Roger Federer\\n(24.2, 28.14), Tekst:  We can even visualize our forest and it looks like this.\\n(24.76, 28.34), Tekst:  data and I got a decent 83% accuracy.\\n(24.96, 28.0), Tekst:  And you might be asking, how do we build this huge tree?\\n(25.08, 27.8), Tekst:  split, dividing the data and checking purity.\\n(25.32, 29.76), Tekst:  Alright so we split the data, first class passengers go one way and everyone else goes\\n(25.64, 27.48), Tekst:  Okay, 10 second cleaning montage.\\n(26.5, 27.5), Tekst:  winners.\\n(27.18, 28.18), Tekst:  my calculations.\\n(27.48, 28.48), Tekst:  Boom!\\n(28.0, 29.68), Tekst:  Well this is the coolest part.\\n(28.14, 29.14), Tekst:  Pretty sick right?\\n(28.7, 29.7), Tekst:  of all time.\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Whisper_timestamped\n",
    "- fork whispera nastawiony na timestampy\n",
    "- w miarę szybki o wiele szybszy od zwykłego whispera i to robiąc obliczenia na cpu\n",
    "- timestampy które daje są dobrej jakości\n",
    "- mam problem z ustawieniem obliczeń na gpu"
   ],
   "id": "beade3f6d7462614"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:41:57.239083Z",
     "start_time": "2025-04-12T07:39:12.834452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import whisper_timestamped as whisper\n",
    "\n",
    "audio = whisper.load_audio(f\"{video_title}.wav\")\n",
    "\n",
    "model = whisper.load_model(\"tiny\", device=\"cuda\")\n",
    "\n",
    "result = whisper.transcribe(model, audio, language=\"en\")"
   ],
   "id": "9d36ede80f0155fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67918/67918 [02:34<00:00, 440.42frames/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:41:57.443821Z",
     "start_time": "2025-04-12T07:41:57.405699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\n",
    "for word_row in result[\"segments\"]:\n",
    "    for row in word_row['words']:\n",
    "        text += f\"[Time: ({row['start']}, {row['end']}) Text:({row['text']})]\\n \""
   ],
   "id": "ba977652b3ed9509",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:41:57.528616Z",
     "start_time": "2025-04-12T07:41:57.459716Z"
    }
   },
   "cell_type": "code",
   "source": "text",
   "id": "d5c32ed7f56ba0e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Time: (0.18, 0.56) Text:(This)]\\n [Time: (0.56, 0.86) Text:(is)]\\n [Time: (0.86, 1.1) Text:(around)]\\n [Time: (1.1, 1.28) Text:(the)]\\n [Time: (1.28, 1.6) Text:(forest,)]\\n [Time: (1.86, 1.96) Text:(a)]\\n [Time: (1.96, 2.26) Text:(powerful)]\\n [Time: (2.26, 2.76) Text:(machine)]\\n [Time: (2.76, 3.14) Text:(learning)]\\n [Time: (3.14, 3.76) Text:(algorithm)]\\n [Time: (3.76, 4.18) Text:(based)]\\n [Time: (4.18, 4.36) Text:(on)]\\n [Time: (4.36, 4.74) Text:(decision)]\\n [Time: (4.74, 5.1) Text:(trees,)]\\n [Time: (5.28, 5.48) Text:(and)]\\n [Time: (5.48, 5.64) Text:(this)]\\n [Time: (5.64, 5.76) Text:(is)]\\n [Time: (5.76, 6.04) Text:(tennis,)]\\n [Time: (6.26, 6.44) Text:(a)]\\n [Time: (6.44, 6.76) Text:(sport)]\\n [Time: (6.76, 7.34) Text:(I'm)]\\n [Time: (7.34, 7.52) Text:(kind)]\\n [Time: (7.52, 7.7) Text:(of)]\\n [Time: (7.7, 8.08) Text:(obsessed)]\\n [Time: (8.08, 8.36) Text:(with.)]\\n [Time: (8.46, 8.66) Text:(In)]\\n [Time: (8.66, 8.9) Text:(this)]\\n [Time: (8.9, 9.22) Text:(video)]\\n [Time: (9.22, 9.58) Text:(I'll)]\\n [Time: (9.58, 9.76) Text:(build)]\\n [Time: (9.76, 9.93) Text:(a)]\\n [Time: (9.93, 10.24) Text:(ramen)]\\n [Time: (10.24, 10.68) Text:(forest,)]\\n [Time: (10.9, 11.06) Text:(throw)]\\n [Time: (11.06, 11.3) Text:(at)]\\n [Time: (11.3, 11.4) Text:(it)]\\n [Time: (11.4, 11.72) Text:(a)]\\n [Time: (11.72, 11.94) Text:(bunch)]\\n [Time: (11.94, 12.14) Text:(of)]\\n [Time: (12.14, 12.44) Text:(tennis)]\\n [Time: (12.44, 12.76) Text:(data)]\\n [Time: (12.76, 13.12) Text:(and)]\\n [Time: (13.12, 13.32) Text:(then)]\\n [Time: (13.32, 13.52) Text:(make)]\\n [Time: (13.52, 13.7) Text:(it)]\\n [Time: (13.7, 14.0) Text:(predict)]\\n [Time: (14.0, 14.42) Text:(tennis)]\\n [Time: (14.42, 14.66) Text:(match)]\\n [Time: (14.66, 15.16) Text:(outcomes)]\\n [Time: (15.36, 15.62) Text:(and)]\\n [Time: (15.62, 15.9) Text:(predict)]\\n [Time: (15.9, 16.18) Text:(the)]\\n [Time: (16.18, 16.5) Text:(winner)]\\n [Time: (16.5, 16.72) Text:(of)]\\n [Time: (16.72, 16.88) Text:(a)]\\n [Time: (16.88, 17.08) Text:(big)]\\n [Time: (17.08, 17.36) Text:(tennis)]\\n [Time: (17.36, 17.76) Text:(tournament)]\\n [Time: (17.76, 18.2) Text:(and)]\\n [Time: (18.2, 18.56) Text:(we'll)]\\n [Time: (18.56, 18.7) Text:(see)]\\n [Time: (18.7, 18.86) Text:(how)]\\n [Time: (18.86, 19.04) Text:(it)]\\n [Time: (19.04, 19.42) Text:(performs.)]\\n [Time: (19.64, 19.84) Text:(But)]\\n [Time: (19.84, 20.24) Text:(first,)]\\n [Time: (20.34, 20.58) Text:(I)]\\n [Time: (20.58, 20.92) Text:(need)]\\n [Time: (20.92, 21.26) Text:(data.)]\\n [Time: (21.52, 21.58) Text:(I)]\\n [Time: (21.58, 21.84) Text:(won)]\\n [Time: (21.84, 22.22) Text:(a)]\\n [Time: (22.22, 22.46) Text:(lot)]\\n [Time: (22.46, 22.6) Text:(of)]\\n [Time: (22.6, 22.84) Text:(data.)]\\n [Time: (23.02, 23.14) Text:(I)]\\n [Time: (23.14, 23.34) Text:(won)]\\n [Time: (23.34, 23.54) Text:(every)]\\n [Time: (23.54, 23.82) Text:(single)]\\n [Time: (23.82, 24.16) Text:(break)]\\n [Time: (24.16, 24.32) Text:(for)]\\n [Time: (24.32, 24.46) Text:(me,)]\\n [Time: (24.56, 24.74) Text:(every)]\\n [Time: (24.74, 25.0) Text:(single)]\\n [Time: (25.0, 25.25) Text:(double)]\\n [Time: (25.25, 25.5) Text:(surf,)]\\n [Time: (25.56, 25.8) Text:(every)]\\n [Time: (25.8, 26.0) Text:(single)]\\n [Time: (26.0, 26.3) Text:(double)]\\n [Time: (26.3, 26.46) Text:(full.)]\\n [Time: (26.62, 26.68) Text:(I)]\\n [Time: (26.68, 26.92) Text:(won)]\\n [Time: (26.92, 27.56) Text:(everything,)]\\n [Time: (27.74, 27.82) Text:(there)]\\n [Time: (27.82, 27.88) Text:(are)]\\n [Time: (27.88, 28.38) Text:(backhands,)]\\n [Time: (28.48, 28.56) Text:(there)]\\n [Time: (28.56, 28.66) Text:(are)]\\n [Time: (28.66, 29.1) Text:(forehands,)]\\n [Time: (29.12, 29.32) Text:(there)]\\n [Time: (29.32, 29.38) Text:(are)]\\n [Time: (29.38, 29.66) Text:(heights,)]\\n [Time: (29.86, 29.88) Text:(there)]\\n [Time: (29.88, 30.12) Text:(are)]\\n [Time: (30.12, 30.3) Text:(ages,)]\\n [Time: (30.5, 30.52) Text:(there)]\\n [Time: (30.52, 30.64) Text:(are)]\\n [Time: (30.64, 30.92) Text:(dots)]\\n [Time: (30.92, 31.18) Text:(named,)]\\n [Time: (31.32, 31.36) Text:(there)]\\n [Time: (31.36, 31.46) Text:(are)]\\n [Time: (31.46, 31.74) Text:(moms)]\\n [Time: (31.74, 31.98) Text:(named.)]\\n [Time: (32.08, 32.22) Text:(There)]\\n [Time: (32.22, 32.36) Text:(are)]\\n [Time: (32.36, 32.7) Text:(gramas,)]\\n [Time: (32.84, 33.18) Text:(secret)]\\n [Time: (33.18, 33.74) Text:(lasagna)]\\n [Time: (33.74, 34.22) Text:(recipe.)]\\n [Time: (34.5, 34.76) Text:(Yeah,)]\\n [Time: (34.94, 34.96) Text:(I)]\\n [Time: (34.96, 35.12) Text:(need)]\\n [Time: (35.12, 35.32) Text:(that)]\\n [Time: (35.32, 35.54) Text:(stuff)]\\n [Time: (35.54, 35.72) Text:(too,)]\\n [Time: (35.84, 35.9) Text:(man.)]\\n [Time: (36.04, 36.1) Text:(I'm)]\\n [Time: (36.1, 36.42) Text:(surviving)]\\n [Time: (36.42, 36.68) Text:(on)]\\n [Time: (36.68, 36.96) Text:(noodles)]\\n [Time: (36.96, 37.26) Text:(over)]\\n [Time: (37.26, 37.46) Text:(here.)]\\n [Time: (37.58, 37.8) Text:(And)]\\n [Time: (37.8, 38.08) Text:(then)]\\n [Time: (38.2, 38.42) Text:(I)]\\n [Time: (38.42, 38.62) Text:(found)]\\n [Time: (38.62, 38.84) Text:(it,)]\\n [Time: (38.98, 39.02) Text:(the)]\\n [Time: (39.02, 39.34) Text:(holy)]\\n [Time: (39.34, 39.84) Text:(grail)]\\n [Time: (39.84, 40.1) Text:(of)]\\n [Time: (40.1, 40.5) Text:(tennis)]\\n [Time: (40.5, 41.06) Text:(datasets,)]\\n [Time: (41.3, 41.42) Text:(a)]\\n [Time: (41.42, 41.68) Text:(filed)]\\n [Time: (41.68, 41.96) Text:(so)]\\n [Time: (41.96, 42.36) Text:(massive,)]\\n [Time: (42.42, 42.84) Text:(so)]\\n [Time: (42.84, 43.24) Text:(detailed)]\\n [Time: (43.24, 43.6) Text:(that)]\\n [Time: (43.6, 44.02) Text:(opening)]\\n [Time: (44.02, 44.06) Text:(it,)]\\n [Time: (44.06, 44.56) Text:(crash)]\\n [Time: (44.56, 44.7) Text:(my)]\\n [Time: (44.7, 45.12) Text:(computer,)]\\n [Time: (45.52, 45.68) Text:(someone)]\\n [Time: (45.68, 46.9) Text:(three-stitestitions)]\\n [Time: (46.9, 47.26) Text:(and)]\\n [Time: (47.26, 47.5) Text:(made)]\\n [Time: (47.5, 47.72) Text:(my)]\\n [Time: (47.72, 48.12) Text:(axle)]\\n [Time: (48.12, 48.52) Text:(back)]\\n [Time: (48.52, 48.72) Text:(for)]\\n [Time: (48.72, 49.18) Text:(mercy.)]\\n [Time: (49.56, 49.88) Text:(The)]\\n [Time: (49.88, 50.2) Text:(famous)]\\n [Time: (50.2, 51.0) Text:(2008)]\\n [Time: (51.26, 51.56) Text:(women)]\\n [Time: (51.56, 51.82) Text:(learn)]\\n [Time: (51.82, 52.14) Text:(final)]\\n [Time: (52.14, 52.46) Text:(between)]\\n [Time: (52.46, 52.86) Text:(Rafa)]\\n [Time: (52.86, 53.0) Text:(and)]\\n [Time: (53.0, 53.42) Text:(Adel)]\\n [Time: (53.42, 53.7) Text:(and)]\\n [Time: (53.7, 54.02) Text:(Roger)]\\n [Time: (54.02, 54.76) Text:(Fredderer.)]\\n [Time: (54.82, 54.84) Text:(I)]\\n [Time: (54.84, 55.0) Text:(got)]\\n [Time: (55.0, 55.22) Text:(it.)]\\n [Time: (55.22, 55.36) Text:(The)]\\n [Time: (55.36, 55.64) Text:(longest)]\\n [Time: (55.64, 56.03) Text:(grinds)]\\n [Time: (56.03, 56.16) Text:(down)]\\n [Time: (56.16, 56.5) Text:(final)]\\n [Time: (56.5, 56.72) Text:(of)]\\n [Time: (56.72, 56.84) Text:(all)]\\n [Time: (56.84, 57.16) Text:(time,)]\\n [Time: (57.24, 57.38) Text:(I)]\\n [Time: (57.38, 57.58) Text:(got)]\\n [Time: (57.58, 57.74) Text:(it.)]\\n [Time: (57.82, 58.04) Text:(Even)]\\n [Time: (58.04, 58.3) Text:(this)]\\n [Time: (58.3, 58.54) Text:(one)]\\n [Time: (58.54, 58.76) Text:(time,)]\\n [Time: (58.86, 59.02) Text:(this)]\\n [Time: (59.02, 59.34) Text:(skid)]\\n [Time: (59.34, 59.54) Text:(bit)]\\n [Time: (59.54, 59.86) Text:(Rafa)]\\n [Time: (59.86, 60.06) Text:(and)]\\n [Time: (60.06, 60.2) Text:(Adel)]\\n [Time: (60.2, 60.42) Text:(and)]\\n [Time: (60.42, 60.74) Text:(Novak)]\\n [Time: (60.74, 61.28) Text:(Jokovitch)]\\n [Time: (61.28, 61.54) Text:(back)]\\n [Time: (61.54, 61.7) Text:(to)]\\n [Time: (61.7, 61.92) Text:(back.)]\\n [Time: (62.06, 62.14) Text:(I)]\\n [Time: (62.14, 62.38) Text:(have)]\\n [Time: (62.38, 62.5) Text:(it.)]\\n [Time: (62.58, 62.72) Text:(I)]\\n [Time: (62.72, 62.88) Text:(have)]\\n [Time: (62.88, 62.9) Text:(it)]\\n [Time: (62.9, 63.12) Text:(all.)]\\n [Time: (63.18, 63.28) Text:(I)]\\n [Time: (63.28, 63.46) Text:(have)]\\n [Time: (63.46, 63.8) Text:(every)]\\n [Time: (63.8, 64.14) Text:(single)]\\n [Time: (64.14, 64.8) Text:(ATP)]\\n [Time: (64.8, 65.06) Text:(as)]\\n [Time: (65.06, 65.18) Text:(a)]\\n [Time: (65.18, 65.4) Text:(session)]\\n [Time: (65.4, 65.56) Text:(of)]\\n [Time: (65.56, 65.78) Text:(tennis)]\\n [Time: (65.78, 66.3) Text:(professionals,)]\\n [Time: (66.6, 66.92) Text:(match)]\\n [Time: (66.92, 67.18) Text:(from)]\\n [Time: (67.18, 67.84) Text:(1981)]\\n [Time: (67.84, 68.2) Text:(to)]\\n [Time: (68.2, 68.82) Text:(2024)]\\n [Time: (68.82, 69.26) Text:(baby.)]\\n [Time: (69.48, 69.58) Text:(But)]\\n [Time: (69.58, 69.8) Text:(before)]\\n [Time: (69.8, 70.14) Text:(using)]\\n [Time: (70.14, 70.42) Text:(this)]\\n [Time: (70.42, 70.66) Text:(data,)]\\n [Time: (70.86, 70.92) Text:(I)]\\n [Time: (70.92, 71.1) Text:(want)]\\n [Time: (71.1, 71.22) Text:(to)]\\n [Time: (71.22, 71.38) Text:(try)]\\n [Time: (71.38, 71.71) Text:(building)]\\n [Time: (71.71, 72.0) Text:(a)]\\n [Time: (72.0, 72.28) Text:(decision)]\\n [Time: (72.28, 72.54) Text:(tree)]\\n [Time: (72.54, 72.72) Text:(from)]\\n [Time: (72.72, 73.12) Text:(scratch.)]\\n [Time: (73.28, 73.56) Text:(That's)]\\n [Time: (73.56, 73.76) Text:(right.)]\\n [Time: (73.88, 74.04) Text:(No)]\\n [Time: (74.04, 74.4) Text:(SK)]\\n [Time: (74.4, 74.68) Text:(learn)]\\n [Time: (74.68, 74.96) Text:(no)]\\n [Time: (74.96, 75.16) Text:(pie)]\\n [Time: (75.16, 75.44) Text:(torch,)]\\n [Time: (75.6, 75.92) Text:(just)]\\n [Time: (75.92, 76.3) Text:(my)]\\n [Time: (76.3, 76.46) Text:(good)]\\n [Time: (76.46, 76.66) Text:(old)]\\n [Time: (76.66, 76.89) Text:(friend)]\\n [Time: (76.89, 77.24) Text:(Nampa)]\\n [Time: (77.24, 77.52) Text:(and)]\\n [Time: (77.52, 77.56) Text:(me.)]\\n [Time: (77.74, 77.9) Text:(And)]\\n [Time: (77.9, 78.16) Text:(decision)]\\n [Time: (78.16, 78.56) Text:(trees)]\\n [Time: (78.56, 78.9) Text:(are)]\\n [Time: (78.9, 79.38) Text:(pretty)]\\n [Time: (79.38, 79.98) Text:(awesome.)]\\n [Time: (80.18, 80.42) Text:(Think)]\\n [Time: (80.42, 80.52) Text:(of)]\\n [Time: (80.52, 80.84) Text:(them)]\\n [Time: (80.84, 81.06) Text:(like)]\\n [Time: (81.06, 81.62) Text:(a)]\\n [Time: (81.62, 81.78) Text:(show's)]\\n [Time: (81.78, 81.94) Text:(your)]\\n [Time: (81.94, 82.18) Text:(own)]\\n [Time: (82.18, 82.6) Text:(adventure)]\\n [Time: (82.72, 82.92) Text:(book,)]\\n [Time: (83.14, 83.16) Text:(but)]\\n [Time: (83.16, 83.3) Text:(instead)]\\n [Time: (83.3, 83.46) Text:(of)]\\n [Time: (83.46, 83.92) Text:(designing)]\\n [Time: (83.92, 84.3) Text:(whether)]\\n [Time: (84.3, 84.58) Text:(you)]\\n [Time: (84.58, 84.8) Text:(fight)]\\n [Time: (84.8, 84.94) Text:(a)]\\n [Time: (84.94, 85.24) Text:(dragon)]\\n [Time: (85.24, 85.42) Text:(or)]\\n [Time: (85.42, 85.84) Text:(runaway,)]\\n [Time: (86.2, 86.34) Text:(it's)]\\n [Time: (86.34, 86.56) Text:(the)]\\n [Time: (86.56, 86.96) Text:(siding)]\\n [Time: (86.96, 87.3) Text:(who)]\\n [Time: (87.3, 87.52) Text:(won)]\\n [Time: (87.52, 87.61) Text:(a)]\\n [Time: (87.61, 87.88) Text:(tennis)]\\n [Time: (87.88, 88.14) Text:(match.)]\\n [Time: (88.34, 88.7) Text:(Let's)]\\n [Time: (88.7, 88.94) Text:(take)]\\n [Time: (88.94, 89.24) Text:(the)]\\n [Time: (89.24, 89.64) Text:(Titanic)]\\n [Time: (89.64, 90.14) Text:(disaster)]\\n [Time: (90.14, 90.42) Text:(as)]\\n [Time: (90.42, 90.56) Text:(an)]\\n [Time: (90.56, 90.88) Text:(example.)]\\n [Time: (91.06, 91.32) Text:(We've)]\\n [Time: (91.32, 91.44) Text:(got)]\\n [Time: (91.44, 91.54) Text:(a)]\\n [Time: (91.54, 91.7) Text:(lot)]\\n [Time: (91.7, 91.84) Text:(of)]\\n [Time: (91.84, 92.1) Text:(data)]\\n [Time: (92.1, 92.3) Text:(on)]\\n [Time: (92.3, 92.82) Text:(passengers,)]\\n [Time: (93.02, 93.38) Text:(things)]\\n [Time: (93.38, 93.8) Text:(like)]\\n [Time: (93.8, 94.1) Text:(their)]\\n [Time: (94.1, 94.44) Text:(age,)]\\n [Time: (94.64, 94.76) Text:(their)]\\n [Time: (94.76, 95.14) Text:(cabin)]\\n [Time: (95.14, 95.56) Text:(and)]\\n [Time: (95.56, 95.82) Text:(ticket)]\\n [Time: (95.82, 96.2) Text:(class.)]\\n [Time: (96.32, 96.56) Text:(As)]\\n [Time: (96.56, 96.62) Text:(a)]\\n [Time: (96.62, 96.98) Text:(gantry)]\\n [Time: (96.98, 97.4) Text:(works)]\\n [Time: (97.4, 97.62) Text:(by)]\\n [Time: (97.62, 98.1) Text:(asking)]\\n [Time: (98.1, 98.42) Text:(a)]\\n [Time: (98.42, 98.64) Text:(series)]\\n [Time: (98.64, 98.9) Text:(of)]\\n [Time: (98.92, 99.24) Text:(yes)]\\n [Time: (99.24, 99.52) Text:(and)]\\n [Time: (99.52, 99.68) Text:(no)]\\n [Time: (99.68, 100.08) Text:(questions)]\\n [Time: (100.08, 100.36) Text:(to)]\\n [Time: (100.36, 100.78) Text:(classify)]\\n [Time: (100.78, 101.14) Text:(whether)]\\n [Time: (101.14, 101.5) Text:(someone)]\\n [Time: (101.5, 102.06) Text:(survived.)]\\n [Time: (102.32, 102.52) Text:(For)]\\n [Time: (102.52, 103.02) Text:(example,)]\\n [Time: (103.38, 103.56) Text:(let's)]\\n [Time: (103.56, 103.82) Text:(take)]\\n [Time: (103.82, 104.16) Text:(Miss)]\\n [Time: (104.16, 104.62) Text:(Elizabeth)]\\n [Time: (104.8, 105.24) Text:(Bonnell.)]\\n [Time: (105.48, 105.58) Text:(A)]\\n [Time: (105.58, 105.78) Text:(simple)]\\n [Time: (105.78, 106.2) Text:(decision)]\\n [Time: (106.2, 106.5) Text:(tree)]\\n [Time: (106.5, 106.8) Text:(might)]\\n [Time: (106.8, 107.22) Text:(start)]\\n [Time: (107.22, 107.7) Text:(by)]\\n [Time: (107.7, 108.08) Text:(asking)]\\n [Time: (108.08, 108.48) Text:(the)]\\n [Time: (108.48, 108.98) Text:(cheapay)]\\n [Time: (108.98, 109.18) Text:(more)]\\n [Time: (109.18, 109.34) Text:(than)]\\n [Time: (109.34, 109.64) Text:(20)]\\n [Time: (109.64, 109.94) Text:(pounds)]\\n [Time: (109.94, 110.16) Text:(for)]\\n [Time: (110.16, 110.34) Text:(her)]\\n [Time: (110.34, 110.68) Text:(ticket.)]\\n [Time: (110.88, 111.08) Text:(Yes)]\\n [Time: (111.08, 111.22) Text:(she)]\\n [Time: (111.22, 111.46) Text:(did.)]\\n [Time: (111.8, 111.82) Text:(So)]\\n [Time: (111.82, 111.98) Text:(we)]\\n [Time: (111.98, 112.16) Text:(go)]\\n [Time: (112.16, 112.48) Text:(left.)]\\n [Time: (112.72, 112.94) Text:(Next)]\\n [Time: (112.94, 113.26) Text:(question.)]\\n [Time: (113.46, 113.6) Text:(Was)]\\n [Time: (113.6, 113.78) Text:(she)]\\n [Time: (113.78, 113.92) Text:(in)]\\n [Time: (113.92, 114.14) Text:(first)]\\n [Time: (114.14, 114.5) Text:(class?)]\\n [Time: (114.72, 114.88) Text:(Yes)]\\n [Time: (114.88, 115.22) Text:(again.)]\\n [Time: (115.46, 115.5) Text:(At)]\\n [Time: (115.5, 115.68) Text:(this)]\\n [Time: (115.68, 115.94) Text:(point,)]\\n [Time: (116.04, 116.32) Text:(our)]\\n [Time: (116.32, 116.54) Text:(tree)]\\n [Time: (116.54, 117.24) Text:(confidently)]\\n [Time: (117.24, 117.94) Text:(predicts)]\\n [Time: (117.94, 118.14) Text:(that)]\\n [Time: (118.14, 118.22) Text:(she)]\\n [Time: (118.22, 118.68) Text:(survived)]\\n [Time: (118.68, 119.28) Text:(because)]\\n [Time: (119.28, 119.5) Text:(well,)]\\n [Time: (119.8, 119.92) Text:(she)]\\n [Time: (119.92, 120.26) Text:(actually)]\\n [Time: (120.26, 120.5) Text:(did.)]\\n [Time: (120.8, 120.92) Text:(And)]\\n [Time: (120.92, 121.04) Text:(we)]\\n [Time: (121.04, 121.22) Text:(can)]\\n [Time: (121.22, 121.43) Text:(use)]\\n [Time: (121.43, 121.66) Text:(this)]\\n [Time: (121.66, 121.88) Text:(tree)]\\n [Time: (121.88, 122.2) Text:(again)]\\n [Time: (122.2, 122.4) Text:(and)]\\n [Time: (122.4, 122.62) Text:(again)]\\n [Time: (122.62, 122.82) Text:(to)]\\n [Time: (122.82, 123.12) Text:(predict)]\\n [Time: (123.12, 123.44) Text:(other)]\\n [Time: (123.44, 123.9) Text:(passengers.)]\\n [Time: (124.26, 124.58) Text:(This)]\\n [Time: (124.58, 124.92) Text:(is)]\\n [Time: (124.92, 125.22) Text:(really)]\\n [Time: (125.22, 125.4) Text:(a)]\\n [Time: (125.4, 125.66) Text:(simple)]\\n [Time: (125.66, 125.94) Text:(tree,)]\\n [Time: (126.2, 126.36) Text:(but)]\\n [Time: (126.36, 126.88) Text:(this)]\\n [Time: (126.88, 127.18) Text:(is)]\\n [Time: (127.18, 127.33) Text:(what)]\\n [Time: (127.33, 127.54) Text:(I)]\\n [Time: (127.54, 127.82) Text:(got)]\\n [Time: (127.82, 128.06) Text:(when)]\\n [Time: (128.06, 128.4) Text:(training)]\\n [Time: (128.4, 128.78) Text:(with)]\\n [Time: (128.78, 128.9) Text:(a)]\\n [Time: (128.9, 129.28) Text:(Titanic)]\\n [Time: (129.28, 129.82) Text:(dataset.)]\\n [Time: (130.1, 130.16) Text:(And)]\\n [Time: (130.16, 130.24) Text:(you)]\\n [Time: (130.24, 130.42) Text:(might)]\\n [Time: (130.42, 130.6) Text:(be)]\\n [Time: (130.6, 130.86) Text:(asking,)]\\n [Time: (131.18, 131.3) Text:(how)]\\n [Time: (131.3, 131.46) Text:(do)]\\n [Time: (131.46, 131.6) Text:(we)]\\n [Time: (131.6, 132.08) Text:(build)]\\n [Time: (132.08, 132.42) Text:(this)]\\n [Time: (132.42, 132.7) Text:(huge)]\\n [Time: (132.74, 133.06) Text:(tree?)]\\n [Time: (133.2, 133.42) Text:(Well,)]\\n [Time: (133.78, 133.9) Text:(this)]\\n [Time: (133.9, 134.16) Text:(is)]\\n [Time: (134.16, 134.2) Text:(the)]\\n [Time: (134.2, 134.5) Text:(coolest)]\\n [Time: (134.5, 134.78) Text:(part.)]\\n [Time: (134.96, 135.12) Text:(We)]\\n [Time: (135.12, 135.36) Text:(don't)]\\n [Time: (135.36, 135.64) Text:(need)]\\n [Time: (135.64, 135.96) Text:(any)]\\n [Time: (135.96, 136.32) Text:(fancy)]\\n [Time: (136.32, 136.96) Text:(algorithm)]\\n [Time: (136.96, 137.32) Text:(like)]\\n [Time: (137.32, 137.52) Text:(with)]\\n [Time: (137.52, 137.76) Text:(neural)]\\n [Time: (137.76, 138.1) Text:(nets,)]\\n [Time: (138.22, 138.5) Text:(no)]\\n [Time: (138.5, 138.9) Text:(matrix)]\\n [Time: (138.9, 139.52) Text:(multiplication,)]\\n [Time: (139.7, 139.92) Text:(no)]\\n [Time: (139.92, 140.16) Text:(gradient)]\\n [Time: (140.16, 140.58) Text:(descent,)]\\n [Time: (140.76, 140.98) Text:(none)]\\n [Time: (140.98, 141.1) Text:(of)]\\n [Time: (141.1, 141.36) Text:(that)]\\n [Time: (141.36, 141.74) Text:(fancy)]\\n [Time: (141.74, 142.12) Text:(crab,)]\\n [Time: (142.34, 142.46) Text:(just)]\\n [Time: (142.46, 142.68) Text:(some)]\\n [Time: (142.68, 143.12) Text:(logic)]\\n [Time: (143.12, 143.52) Text:(and)]\\n [Time: (143.52, 143.65) Text:(some)]\\n [Time: (143.65, 144.14) Text:(simple)]\\n [Time: (144.14, 144.62) Text:(arithmetic.)]\\n [Time: (144.94, 145.26) Text:(Here's)]\\n [Time: (145.26, 145.36) Text:(how)]\\n [Time: (145.36, 145.58) Text:(this)]\\n [Time: (145.58, 145.96) Text:(works.)]\\n [Time: (146.16, 146.52) Text:(First)]\\n [Time: (146.52, 146.74) Text:(we)]\\n [Time: (146.74, 146.96) Text:(grab)]\\n [Time: (146.96, 147.16) Text:(all)]\\n [Time: (147.16, 147.34) Text:(the)]\\n [Time: (147.34, 147.68) Text:(Titanic)]\\n [Time: (147.68, 148.04) Text:(data)]\\n [Time: (148.04, 148.38) Text:(and)]\\n [Time: (148.38, 148.56) Text:(start)]\\n [Time: (148.56, 148.8) Text:(with)]\\n [Time: (148.8, 148.96) Text:(an)]\\n [Time: (148.96, 149.16) Text:(empty)]\\n [Time: (149.16, 149.4) Text:(tree.)]\\n [Time: (149.56, 149.86) Text:(Now)]\\n [Time: (149.86, 150.06) Text:(our)]\\n [Time: (150.06, 150.3) Text:(goal)]\\n [Time: (150.3, 150.54) Text:(is)]\\n [Time: (150.54, 150.7) Text:(to)]\\n [Time: (150.7, 150.94) Text:(find)]\\n [Time: (150.94, 151.18) Text:(the)]\\n [Time: (151.18, 151.64) Text:(variable)]\\n [Time: (151.64, 152.0) Text:(that)]\\n [Time: (152.0, 152.32) Text:(best)]\\n [Time: (152.32, 152.8) Text:(splits)]\\n [Time: (152.8, 153.1) Text:(the)]\\n [Time: (153.1, 153.58) Text:(passengers)]\\n [Time: (153.58, 154.06) Text:(into)]\\n [Time: (154.06, 154.62) Text:(survivors)]\\n [Time: (154.62, 155.0) Text:(and)]\\n [Time: (155.0, 155.84) Text:(non-survivors.)]\\n [Time: (155.98, 156.26) Text:(Turns)]\\n [Time: (156.26, 156.54) Text:(out)]\\n [Time: (156.54, 156.8) Text:(that)]\\n [Time: (156.8, 156.94) Text:(the)]\\n [Time: (156.94, 157.18) Text:(most)]\\n [Time: (157.18, 157.7) Text:(powerful)]\\n [Time: (157.7, 158.3) Text:(first)]\\n [Time: (158.3, 158.74) Text:(split)]\\n [Time: (158.74, 159.06) Text:(is)]\\n [Time: (159.06, 159.6) Text:(passenger)]\\n [Time: (159.6, 160.1) Text:(class.)]\\n [Time: (160.3, 160.44) Text:(All)]\\n [Time: (160.44, 160.54) Text:(right,)]\\n [Time: (160.68, 160.74) Text:(so)]\\n [Time: (160.74, 160.9) Text:(we)]\\n [Time: (160.9, 161.1) Text:(split)]\\n [Time: (161.1, 161.28) Text:(the)]\\n [Time: (161.28, 161.44) Text:(data.)]\\n [Time: (161.52, 161.76) Text:(First)]\\n [Time: (161.76, 161.98) Text:(class)]\\n [Time: (161.98, 162.38) Text:(passengers)]\\n [Time: (162.38, 162.78) Text:(go)]\\n [Time: (162.78, 163.16) Text:(one)]\\n [Time: (163.16, 163.42) Text:(way)]\\n [Time: (163.42, 163.78) Text:(and)]\\n [Time: (163.78, 164.16) Text:(everyone)]\\n [Time: (164.16, 164.52) Text:(else)]\\n [Time: (164.52, 164.84) Text:(goes)]\\n [Time: (164.84, 165.12) Text:(this)]\\n [Time: (165.12, 165.36) Text:(way.)]\\n [Time: (165.46, 165.64) Text:(But)]\\n [Time: (165.64, 165.8) Text:(hold)]\\n [Time: (165.8, 166.02) Text:(up,)]\\n [Time: (166.18, 166.46) Text:(there's)]\\n [Time: (166.46, 166.66) Text:(still)]\\n [Time: (166.72, 166.96) Text:(some)]\\n [Time: (166.96, 167.56) Text:(impurity,)]\\n [Time: (167.84, 168.1) Text:(not)]\\n [Time: (168.1, 168.52) Text:(everyone)]\\n [Time: (168.52, 168.84) Text:(in)]\\n [Time: (168.84, 169.08) Text:(first)]\\n [Time: (169.08, 169.48) Text:(class)]\\n [Time: (169.48, 170.12) Text:(survived.)]\\n [Time: (170.44, 170.54) Text:(So)]\\n [Time: (170.54, 170.76) Text:(what)]\\n [Time: (170.76, 171.1) Text:(now?)]\\n [Time: (171.2, 171.38) Text:(Well,)]\\n [Time: (171.46, 171.66) Text:(we)]\\n [Time: (171.66, 171.9) Text:(look)]\\n [Time: (171.9, 172.16) Text:(for)]\\n [Time: (172.16, 172.3) Text:(the)]\\n [Time: (172.3, 172.62) Text:(next)]\\n [Time: (172.62, 173.04) Text:(best)]\\n [Time: (173.04, 173.4) Text:(split.)]\\n [Time: (173.58, 173.74) Text:(And)]\\n [Time: (173.74, 173.94) Text:(guess)]\\n [Time: (173.94, 174.14) Text:(what?)]\\n [Time: (174.22, 174.3) Text:(The)]\\n [Time: (174.3, 174.68) Text:(strongest)]\\n [Time: (174.68, 175.4) Text:(predictor)]\\n [Time: (175.4, 175.74) Text:(now)]\\n [Time: (175.74, 176.0) Text:(is)]\\n [Time: (176.0, 176.54) Text:(sex.)]\\n [Time: (177.0, 177.16) Text:(So)]\\n [Time: (177.16, 177.26) Text:(we)]\\n [Time: (177.26, 177.64) Text:(slice)]\\n [Time: (177.64, 178.0) Text:(the)]\\n [Time: (178.0, 178.2) Text:(data)]\\n [Time: (178.2, 178.46) Text:(again)]\\n [Time: (178.46, 178.76) Text:(and)]\\n [Time: (178.76, 179.2) Text:(boom,)]\\n [Time: (179.4, 179.68) Text:(every)]\\n [Time: (179.68, 180.06) Text:(female)]\\n [Time: (180.06, 180.38) Text:(in)]\\n [Time: (180.38, 180.62) Text:(first)]\\n [Time: (180.62, 180.92) Text:(class)]\\n [Time: (180.92, 181.42) Text:(survived.)]\\n [Time: (181.64, 181.96) Text:(That)]\\n [Time: (181.96, 182.22) Text:(means)]\\n [Time: (182.22, 182.48) Text:(we)]\\n [Time: (182.48, 182.74) Text:(have)]\\n [Time: (182.74, 182.96) Text:(had)]\\n [Time: (182.96, 183.2) Text:(a)]\\n [Time: (183.2, 183.38) Text:(pure)]\\n [Time: (183.38, 183.62) Text:(note)]\\n [Time: (183.62, 183.98) Text:(which)]\\n [Time: (183.98, 184.2) Text:(we)]\\n [Time: (184.2, 184.54) Text:(marked)]\\n [Time: (184.54, 184.81) Text:(as)]\\n [Time: (184.81, 185.32) Text:(survived.)]\\n [Time: (185.68, 185.78) Text:(And)]\\n [Time: (185.78, 185.92) Text:(for)]\\n [Time: (185.92, 186.06) Text:(the)]\\n [Time: (186.06, 186.3) Text:(other)]\\n [Time: (186.3, 186.72) Text:(branches)]\\n [Time: (186.72, 186.98) Text:(of)]\\n [Time: (186.98, 187.08) Text:(the)]\\n [Time: (187.08, 187.28) Text:(tree,)]\\n [Time: (187.44, 187.62) Text:(we)]\\n [Time: (187.62, 187.8) Text:(keep)]\\n [Time: (187.8, 188.14) Text:(repeating)]\\n [Time: (188.14, 188.44) Text:(this)]\\n [Time: (188.44, 188.92) Text:(process.)]\\n [Time: (189.06, 189.38) Text:(Finding)]\\n [Time: (189.38, 189.66) Text:(the)]\\n [Time: (189.66, 189.88) Text:(best)]\\n [Time: (189.94, 190.22) Text:(split,)]\\n [Time: (190.36, 190.58) Text:(dividing)]\\n [Time: (190.58, 190.82) Text:(the)]\\n [Time: (190.82, 191.12) Text:(data)]\\n [Time: (191.12, 191.54) Text:(and)]\\n [Time: (191.54, 191.84) Text:(checking)]\\n [Time: (191.84, 192.28) Text:(purity.)]\\n [Time: (192.58, 192.84) Text:(Until)]\\n [Time: (192.84, 193.36) Text:(Todd,)]\\n [Time: (193.52, 193.54) Text:(Todd,)]\\n [Time: (193.8, 194.04) Text:(we)]\\n [Time: (194.04, 194.3) Text:(have)]\\n [Time: (194.3, 194.82) Text:(ourselves)]\\n [Time: (194.82, 195.16) Text:(a)]\\n [Time: (195.16, 195.4) Text:(fully)]\\n [Time: (195.4, 195.82) Text:(grown,)]\\n [Time: (195.92, 196.56) Text:(absolutely)]\\n [Time: (196.56, 197.34) Text:(magnificent)]\\n [Time: (197.34, 197.94) Text:(decision)]\\n [Time: (197.94, 198.22) Text:(tree.)]\\n [Time: (198.28, 198.6) Text:(Woo,)]\\n [Time: (198.78, 199.0) Text:(let's)]\\n [Time: (199.0, 199.24) Text:(go.)]\\n [Time: (199.36, 199.92) Text:(Implementing)]\\n [Time: (199.92, 200.1) Text:(this)]\\n [Time: (200.1, 200.22) Text:(in)]\\n [Time: (200.22, 200.5) Text:(Python)]\\n [Time: (200.5, 200.88) Text:(was)]\\n [Time: (200.88, 201.1) Text:(actually)]\\n [Time: (201.1, 201.76) Text:(pre-strait)]\\n [Time: (201.76, 202.14) Text:(forward,)]\\n [Time: (202.38, 202.76) Text:(but)]\\n [Time: (202.76, 202.92) Text:(I)]\\n [Time: (202.92, 203.12) Text:(don't)]\\n [Time: (203.12, 203.34) Text:(think)]\\n [Time: (203.34, 203.68) Text:(it's)]\\n [Time: (203.68, 203.72) Text:(going)]\\n [Time: (203.72, 203.84) Text:(to)]\\n [Time: (203.84, 203.96) Text:(be)]\\n [Time: (203.96, 204.28) Text:(very)]\\n [Time: (204.28, 204.62) Text:(fast.)]\\n [Time: (205.84, 206.12) Text:(Great,)]\\n [Time: (206.38, 206.5) Text:(so)]\\n [Time: (206.5, 206.8) Text:(now)]\\n [Time: (206.8, 206.94) Text:(we)]\\n [Time: (206.94, 207.1) Text:(have)]\\n [Time: (207.1, 207.4) Text:(a)]\\n [Time: (207.4, 207.54) Text:(fully)]\\n [Time: (207.66, 207.96) Text:(working)]\\n [Time: (207.96, 208.4) Text:(decision)]\\n [Time: (208.4, 208.64) Text:(tree)]\\n [Time: (208.64, 209.22) Text:(classifier.)]\\n [Time: (209.42, 209.76) Text:(But)]\\n [Time: (209.76, 210.22) Text:(before)]\\n [Time: (210.22, 210.48) Text:(we)]\\n [Time: (210.48, 210.72) Text:(use)]\\n [Time: (210.72, 210.98) Text:(it)]\\n [Time: (210.98, 211.14) Text:(to)]\\n [Time: (211.14, 211.34) Text:(predict)]\\n [Time: (211.34, 211.58) Text:(the)]\\n [Time: (211.58, 211.8) Text:(outcome)]\\n [Time: (211.8, 211.98) Text:(of)]\\n [Time: (211.98, 212.18) Text:(the)]\\n [Time: (212.18, 212.28) Text:(10)]\\n [Time: (212.28, 212.36) Text:(as)]\\n [Time: (212.36, 212.66) Text:(much)]\\n [Time: (212.66, 213.02) Text:(as)]\\n [Time: (213.02, 213.24) Text:(and)]\\n [Time: (213.24, 213.58) Text:(gamble)]\\n [Time: (213.58, 213.92) Text:(some)]\\n [Time: (213.92, 214.2) Text:(money,)]\\n [Time: (214.72, 214.8) Text:(we)]\\n [Time: (214.8, 215.08) Text:(need)]\\n [Time: (215.08, 215.18) Text:(to)]\\n [Time: (215.18, 215.42) Text:(clean)]\\n [Time: (215.42, 215.68) Text:(up)]\\n [Time: (215.68, 215.76) Text:(the)]\\n [Time: (215.76, 215.96) Text:(10)]\\n [Time: (215.96, 216.1) Text:(in)]\\n [Time: (216.1, 216.3) Text:(state.)]\\n [Time: (216.44, 216.62) Text:(Because)]\\n [Time: (216.62, 216.98) Text:(it's)]\\n [Time: (216.98, 217.26) Text:(looking)]\\n [Time: (217.26, 217.6) Text:(kind)]\\n [Time: (217.6, 217.8) Text:(of)]\\n [Time: (217.8, 218.1) Text:(close.)]\\n [Time: (218.24, 218.48) Text:(Okay,)]\\n [Time: (218.62, 218.82) Text:(10)]\\n [Time: (218.82, 219.1) Text:(second)]\\n [Time: (219.1, 219.44) Text:(cleaning)]\\n [Time: (219.44, 219.94) Text:(montage.)]\\n [Time: (220.3, 220.5) Text:(Boom,)]\\n [Time: (220.58, 220.9) Text:(combined)]\\n [Time: (220.9, 221.08) Text:(the)]\\n [Time: (221.08, 221.28) Text:(data)]\\n [Time: (221.28, 221.6) Text:(sets,)]\\n [Time: (221.7, 222.0) Text:(remove)]\\n [Time: (222.0, 222.38) Text:(empty)]\\n [Time: (222.38, 222.74) Text:(data,)]\\n [Time: (222.98, 223.12) Text:(get)]\\n [Time: (223.12, 223.28) Text:(the)]\\n [Time: (223.28, 223.6) Text:(ranking)]\\n [Time: (223.6, 224.04) Text:(difference)]\\n [Time: (224.04, 224.4) Text:(between)]\\n [Time: (224.4, 225.22) Text:(winner-losing,)]\\n [Time: (225.5, 225.72) Text:(do)]\\n [Time: (225.72, 226.46) Text:(this)]\\n [Time: (226.46, 227.02) Text:(bullsh-t,)]\\n [Time: (227.06, 227.24) Text:(okay?)]\\n [Time: (227.34, 227.5) Text:(But)]\\n [Time: (227.5, 227.54) Text:(the)]\\n [Time: (227.54, 227.7) Text:(beam)]\\n [Time: (227.7, 227.88) Text:(by)]\\n [Time: (227.88, 227.98) Text:(the)]\\n [Time: (227.98, 228.22) Text:(boom?)]\\n [Time: (228.22, 228.62) Text:(My)]\\n [Time: (228.62, 228.96) Text:(beautiful)]\\n [Time: (228.96, 229.32) Text:(data)]\\n [Time: (229.32, 229.6) Text:(set)]\\n [Time: (229.6, 229.8) Text:(is)]\\n [Time: (229.8, 230.16) Text:(complete.)]\\n [Time: (230.48, 230.64) Text:(It)]\\n [Time: (230.64, 230.96) Text:(has)]\\n [Time: (230.96, 232.36) Text:(95,000)]\\n [Time: (232.36, 232.56) Text:(tennis)]\\n [Time: (232.56, 232.88) Text:(matches)]\\n [Time: (232.88, 233.18) Text:(with)]\\n [Time: (233.18, 233.36) Text:(their)]\\n [Time: (233.36, 233.92) Text:(corresponding)]\\n [Time: (234.1, 234.56) Text:(statistics.)]\\n [Time: (234.84, 235.08) Text:(And)]\\n [Time: (235.08, 235.38) Text:(there's)]\\n [Time: (235.38, 235.56) Text:(a)]\\n [Time: (235.56, 235.74) Text:(lot)]\\n [Time: (235.74, 235.94) Text:(of)]\\n [Time: (235.94, 236.44) Text:(statistics)]\\n [Time: (236.44, 236.8) Text:(I)]\\n [Time: (236.8, 237.22) Text:(calculated,)]\\n [Time: (237.42, 237.54) Text:(let)]\\n [Time: (237.54, 237.66) Text:(me)]\\n [Time: (237.66, 237.8) Text:(tell)]\\n [Time: (237.8, 237.92) Text:(you)]\\n [Time: (237.92, 238.08) Text:(that.)]\\n [Time: (238.14, 238.36) Text:(For)]\\n [Time: (238.36, 238.8) Text:(example,)]\\n [Time: (238.94, 239.16) Text:(the)]\\n [Time: (239.16, 239.7) Text:(head-to-head)]\\n [Time: (239.7, 239.94) Text:(for)]\\n [Time: (239.94, 240.26) Text:(every)]\\n [Time: (240.26, 240.58) Text:(match.)]\\n [Time: (240.7, 240.86) Text:(That)]\\n [Time: (240.86, 241.1) Text:(is,)]\\n [Time: (241.24, 241.34) Text:(the)]\\n [Time: (241.34, 241.52) Text:(number)]\\n [Time: (241.52, 241.72) Text:(of)]\\n [Time: (241.72, 241.9) Text:(times)]\\n [Time: (241.9, 242.08) Text:(a)]\\n [Time: (242.08, 242.28) Text:(player)]\\n [Time: (242.28, 242.48) Text:(has)]\\n [Time: (242.48, 242.78) Text:(won)]\\n [Time: (242.78, 243.06) Text:(or)]\\n [Time: (243.06, 243.46) Text:(lost)]\\n [Time: (243.46, 243.9) Text:(against)]\\n [Time: (244.0, 244.36) Text:(another)]\\n [Time: (244.36, 244.62) Text:(player.)]\\n [Time: (244.76, 245.0) Text:(The)]\\n [Time: (245.0, 245.32) Text:(players)]\\n [Time: (245.32, 245.82) Text:(age)]\\n [Time: (245.82, 246.42) Text:(difference,)]\\n [Time: (246.66, 246.82) Text:(their)]\\n [Time: (246.82, 247.06) Text:(high)]\\n [Time: (247.06, 247.56) Text:(difference,)]\\n [Time: (247.74, 247.9) Text:(the)]\\n [Time: (247.9, 248.14) Text:(number)]\\n [Time: (248.14, 248.32) Text:(of)]\\n [Time: (248.32, 248.82) Text:(matches)]\\n [Time: (248.82, 249.2) Text:(won)]\\n [Time: (249.2, 249.38) Text:(in)]\\n [Time: (249.38, 249.48) Text:(the)]\\n [Time: (249.48, 249.7) Text:(last)]\\n [Time: (249.7, 249.94) Text:(50)]\\n [Time: (249.94, 250.36) Text:(matches.)]\\n [Time: (250.58, 250.7) Text:(And)]\\n [Time: (250.7, 250.8) Text:(a)]\\n [Time: (250.8, 251.0) Text:(bunch)]\\n [Time: (251.0, 251.12) Text:(of)]\\n [Time: (251.12, 251.42) Text:(other)]\\n [Time: (251.42, 251.88) Text:(stats)]\\n [Time: (251.88, 252.32) Text:(that)]\\n [Time: (252.32, 252.62) Text:(I)]\\n [Time: (252.62, 252.92) Text:(won't)]\\n [Time: (252.92, 252.98) Text:(get)]\\n [Time: (252.98, 253.28) Text:(into.)]\\n [Time: (253.64, 253.8) Text:(It's)]\\n [Time: (253.8, 254.0) Text:(a)]\\n [Time: (254.0, 254.2) Text:(lot.)]\\n [Time: (254.36, 254.54) Text:(But)]\\n [Time: (254.54, 254.84) Text:(before)]\\n [Time: (254.84, 255.06) Text:(we)]\\n [Time: (255.06, 255.38) Text:(throw)]\\n [Time: (255.58, 255.84) Text:(all)]\\n [Time: (255.84, 256.14) Text:(this)]\\n [Time: (256.14, 256.26) Text:(stuff)]\\n [Time: (256.26, 256.4) Text:(to)]\\n [Time: (256.4, 256.54) Text:(our)]\\n [Time: (256.54, 257.1) Text:(classifier,)]\\n [Time: (257.44, 257.5) Text:(we)]\\n [Time: (257.5, 257.76) Text:(need)]\\n [Time: (257.76, 257.92) Text:(to)]\\n [Time: (257.92, 258.16) Text:(plot)]\\n [Time: (258.16, 258.46) Text:(our)]\\n [Time: (258.46, 258.74) Text:(data,)]\\n [Time: (258.88, 259.14) Text:(plot,)]\\n [Time: (259.36, 259.5) Text:(plot,)]\\n [Time: (259.52, 259.64) Text:(plot,)]\\n [Time: (259.92, 259.94) Text:(plot,)]\\n [Time: (260.3, 260.38) Text:(so)]\\n [Time: (260.38, 260.7) Text:(I)]\\n [Time: (260.7, 260.98) Text:(cooked)]\\n [Time: (260.98, 261.21) Text:(up)]\\n [Time: (261.21, 261.48) Text:(a)]\\n [Time: (261.48, 261.74) Text:(quick)]\\n [Time: (261.74, 262.34) Text:(SNS)]\\n [Time: (262.34, 262.56) Text:(bear)]\\n [Time: (262.56, 262.82) Text:(plot)]\\n [Time: (262.82, 263.46) Text:(and)]\\n [Time: (263.46, 263.64) Text:(wow,)]\\n [Time: (263.84, 263.86) Text:(I)]\\n [Time: (263.86, 264.04) Text:(got)]\\n [Time: (264.04, 264.32) Text:(this)]\\n [Time: (264.32, 264.62) Text:(beauty.)]\\n [Time: (264.76, 264.94) Text:(A)]\\n [Time: (264.94, 265.08) Text:(bunch)]\\n [Time: (265.08, 265.3) Text:(of)]\\n [Time: (265.3, 265.64) Text:(bear)]\\n [Time: (265.64, 265.86) Text:(balls)]\\n [Time: (265.86, 266.26) Text:(plotted)]\\n [Time: (266.26, 266.6) Text:(against)]\\n [Time: (266.6, 266.88) Text:(each)]\\n [Time: (266.88, 267.16) Text:(other)]\\n [Time: (267.3, 267.56) Text:(showing)]\\n [Time: (267.56, 268.04) Text:(us)]\\n [Time: (268.04, 268.38) Text:(some)]\\n [Time: (268.38, 268.96) Text:(interesting)]\\n [Time: (268.96, 269.54) Text:(patterns.)]\\n [Time: (269.8, 269.92) Text:(Of)]\\n [Time: (269.92, 270.16) Text:(course)]\\n [Time: (270.16, 270.46) Text:(some)]\\n [Time: (270.46, 270.72) Text:(bear)]\\n [Time: (270.72, 270.94) Text:(balls)]\\n [Time: (270.94, 271.3) Text:(are)]\\n [Time: (271.3, 271.76) Text:(absolutely)]\\n [Time: (271.76, 272.32) Text:(useless,)]\\n [Time: (272.62, 272.82) Text:(like)]\\n [Time: (272.82, 273.08) Text:(player)]\\n [Time: (273.08, 273.4) Text:(ID,)]\\n [Time: (273.58, 273.8) Text:(but)]\\n [Time: (273.8, 273.96) Text:(I)]\\n [Time: (273.96, 274.16) Text:(want)]\\n [Time: (274.16, 274.24) Text:(to)]\\n [Time: (274.24, 274.38) Text:(draw)]\\n [Time: (274.38, 274.5) Text:(your)]\\n [Time: (274.5, 274.94) Text:(attention)]\\n [Time: (274.94, 275.28) Text:(to)]\\n [Time: (275.28, 275.72) Text:(this)]\\n [Time: (275.72, 275.94) Text:(one.)]\\n [Time: (276.04, 276.36) Text:(Player)]\\n [Time: (276.36, 276.96) Text:(ELO.)]\\n [Time: (277.14, 277.32) Text:(Because)]\\n [Time: (277.32, 277.66) Text:(it)]\\n [Time: (277.66, 277.86) Text:(seems)]\\n [Time: (277.86, 278.04) Text:(to)]\\n [Time: (278.04, 278.18) Text:(be)]\\n [Time: (278.18, 278.58) Text:(splitting)]\\n [Time: (278.58, 279.0) Text:(data)]\\n [Time: (279.0, 279.48) Text:(really)]\\n [Time: (279.48, 279.7) Text:(well.)]\\n [Time: (279.86, 280.02) Text:(So)]\\n [Time: (280.02, 280.3) Text:(let)]\\n [Time: (280.3, 280.5) Text:(me)]\\n [Time: (280.5, 280.68) Text:(show)]\\n [Time: (280.68, 280.96) Text:(you)]\\n [Time: (280.96, 281.12) Text:(how)]\\n [Time: (281.12, 281.38) Text:(I)]\\n [Time: (281.38, 281.84) Text:(calculated)]\\n [Time: (281.84, 282.28) Text:(this.)]\\n [Time: (282.38, 282.64) Text:(The)]\\n [Time: (282.64, 282.94) Text:(ELO)]\\n [Time: (282.94, 283.24) Text:(rating)]\\n [Time: (283.24, 283.72) Text:(system)]\\n [Time: (283.72, 283.98) Text:(is)]\\n [Time: (284.08, 284.2) Text:(a)]\\n [Time: (284.2, 284.3) Text:(way)]\\n [Time: (284.3, 284.42) Text:(to)]\\n [Time: (284.42, 284.96) Text:(approximate)]\\n [Time: (284.96, 285.3) Text:(a)]\\n [Time: (285.3, 285.72) Text:(player's)]\\n [Time: (285.72, 285.94) Text:(skill)]\\n [Time: (285.94, 286.22) Text:(level.)]\\n [Time: (286.54, 286.66) Text:(It's)]\\n [Time: (286.66, 287.06) Text:(mostly)]\\n [Time: (287.06, 287.54) Text:(commonly)]\\n [Time: (287.54, 287.96) Text:(used)]\\n [Time: (287.96, 288.22) Text:(in)]\\n [Time: (288.22, 288.5) Text:(chess,)]\\n [Time: (288.68, 288.9) Text:(but)]\\n [Time: (288.9, 289.04) Text:(I)]\\n [Time: (289.04, 289.32) Text:(decided)]\\n [Time: (289.32, 289.58) Text:(to)]\\n [Time: (289.58, 289.72) Text:(apply)]\\n [Time: (289.72, 289.9) Text:(it)]\\n [Time: (289.9, 289.92) Text:(to)]\\n [Time: (289.92, 290.04) Text:(my)]\\n [Time: (290.04, 290.34) Text:(tennis)]\\n [Time: (290.34, 290.72) Text:(dataset.)]\\n [Time: (290.9, 291.24) Text:(Let's)]\\n [Time: (291.24, 291.5) Text:(take)]\\n [Time: (291.5, 291.84) Text:(Roger)]\\n [Time: (291.84, 292.5) Text:(Frotherer)]\\n [Time: (292.5, 292.62) Text:(as)]\\n [Time: (292.62, 292.76) Text:(an)]\\n [Time: (292.76, 293.08) Text:(example.)]\\n [Time: (293.32, 293.52) Text:(As)]\\n [Time: (293.52, 293.68) Text:(a)]\\n [Time: (293.68, 293.7) Text:(star)]\\n [Time: (293.7, 293.88) Text:(of)]\\n [Time: (293.88, 294.08) Text:(his)]\\n [Time: (294.08, 294.34) Text:(career,)]\\n [Time: (294.44, 294.76) Text:(his)]\\n [Time: (294.76, 295.1) Text:(ELO)]\\n [Time: (295.1, 295.38) Text:(rating)]\\n [Time: (295.38, 295.62) Text:(was)]\\n [Time: (295.62, 295.92) Text:(around)]\\n [Time: (295.92, 296.58) Text:(1500.)]\\n [Time: (296.88, 297.1) Text:(Pretty)]\\n [Time: (297.1, 297.5) Text:(average.)]\\n [Time: (297.68, 298.08) Text:(But)]\\n [Time: (298.08, 298.32) Text:(as)]\\n [Time: (298.32, 298.52) Text:(he)]\\n [Time: (298.52, 298.84) Text:(kept)]\\n [Time: (298.84, 299.16) Text:(winning)]\\n [Time: (299.16, 299.62) Text:(matches,)]\\n [Time: (299.8, 300.02) Text:(his)]\\n [Time: (300.02, 300.28) Text:(rating)]\\n [Time: (300.28, 301.3) Text:(skyrocketed.)]\\n [Time: (301.32, 301.74) Text:(Eventually)]\\n [Time: (301.74, 302.2) Text:(becoming)]\\n [Time: (302.2, 302.72) Text:(one)]\\n [Time: (302.72, 302.8) Text:(of)]\\n [Time: (302.8, 302.88) Text:(the)]\\n [Time: (302.88, 303.16) Text:(greatest)]\\n [Time: (303.16, 303.56) Text:(players)]\\n [Time: (303.56, 303.88) Text:(of)]\\n [Time: (303.88, 304.1) Text:(all)]\\n [Time: (304.1, 304.36) Text:(time.)]\\n [Time: (304.5, 304.78) Text:(Now,)]\\n [Time: (305.08, 305.28) Text:(here's)]\\n [Time: (305.28, 305.48) Text:(his)]\\n [Time: (305.48, 305.82) Text:(ELO)]\\n [Time: (305.82, 306.26) Text:(progression)]\\n [Time: (306.42, 306.72) Text:(plotted)]\\n [Time: (306.72, 307.16) Text:(against)]\\n [Time: (307.16, 307.56) Text:(every)]\\n [Time: (307.56, 307.9) Text:(tennis)]\\n [Time: (307.9, 308.24) Text:(player)]\\n [Time: (308.24, 308.62) Text:(ever.)]\\n [Time: (308.72, 308.86) Text:(As)]\\n [Time: (308.86, 308.96) Text:(you)]\\n [Time: (308.96, 309.2) Text:(can)]\\n [Time: (309.2, 309.38) Text:(see,)]\\n [Time: (309.54, 309.58) Text:(he)]\\n [Time: (309.58, 309.76) Text:(is)]\\n [Time: (309.76, 310.14) Text:(way)]\\n [Time: (310.14, 310.38) Text:(up)]\\n [Time: (310.38, 310.5) Text:(there.)]\\n [Time: (310.66, 310.78) Text:(And)]\\n [Time: (310.78, 310.92) Text:(if)]\\n [Time: (310.92, 311.1) Text:(you're)]\\n [Time: (311.1, 311.38) Text:(wondering)]\\n [Time: (311.46, 311.74) Text:(about)]\\n [Time: (311.74, 311.98) Text:(this)]\\n [Time: (311.98, 312.2) Text:(two)]\\n [Time: (312.2, 312.44) Text:(other)]\\n [Time: (312.44, 312.78) Text:(lines,)]\\n [Time: (312.98, 313.36) Text:(naturally)]\\n [Time: (313.36, 313.72) Text:(those)]\\n [Time: (313.72, 313.94) Text:(are)]\\n [Time: (313.94, 314.22) Text:(Rafa)]\\n [Time: (314.22, 314.58) Text:(Nadal)]\\n [Time: (314.58, 314.86) Text:(at)]\\n [Time: (314.86, 315.16) Text:(Nobba)]\\n [Time: (315.16, 315.62) Text:(Jogovic,)]\\n [Time: (315.8, 315.86) Text:(two)]\\n [Time: (315.86, 316.24) Text:(other)]\\n [Time: (316.24, 316.56) Text:(tennis)]\\n [Time: (316.56, 316.94) Text:(legends.)]\\n [Time: (317.2, 317.36) Text:(And)]\\n [Time: (317.36, 317.42) Text:(the)]\\n [Time: (317.42, 317.62) Text:(cool)]\\n [Time: (317.62, 317.86) Text:(thing)]\\n [Time: (317.86, 318.04) Text:(is)]\\n [Time: (318.04, 318.32) Text:(that)]\\n [Time: (318.32, 318.54) Text:(ELO)]\\n [Time: (318.54, 318.78) Text:(is)]\\n [Time: (318.78, 319.1) Text:(fairly)]\\n [Time: (319.1, 319.56) Text:(easy)]\\n [Time: (319.56, 319.72) Text:(to)]\\n [Time: (319.72, 320.0) Text:(code.)]\\n [Time: (320.2, 320.5) Text:(Let's)]\\n [Time: (320.5, 320.68) Text:(take)]\\n [Time: (320.68, 320.86) Text:(the)]\\n [Time: (320.86, 321.52) Text:(2020-3)]\\n [Time: (321.52, 322.08) Text:(Wimmelon)]\\n [Time: (322.08, 322.36) Text:(final)]\\n [Time: (322.38, 322.68) Text:(between)]\\n [Time: (322.68, 323.1) Text:(Carlos)]\\n [Time: (323.1, 323.76) Text:(Alcaras)]\\n [Time: (323.76, 324.06) Text:(and)]\\n [Time: (324.06, 324.46) Text:(Nobac)]\\n [Time: (324.46, 324.94) Text:(Jogovic.)]\\n [Time: (325.08, 325.5) Text:(Alcarath)]\\n [Time: (325.5, 325.78) Text:(was)]\\n [Time: (325.78, 326.06) Text:(rated)]\\n [Time: (326.06, 326.4) Text:(about)]\\n [Time: (326.4, 327.66) Text:(263)]\\n [Time: (327.66, 327.96) Text:(and)]\\n [Time: (327.96, 328.4) Text:(Jogovic)]\\n [Time: (328.4, 328.6) Text:(was)]\\n [Time: (328.6, 328.86) Text:(rated)]\\n [Time: (328.9, 329.24) Text:(about)]\\n [Time: (329.24, 330.74) Text:(2120,)]\\n [Time: (330.92, 331.18) Text:(according)]\\n [Time: (331.18, 331.58) Text:(to)]\\n [Time: (331.58, 331.98) Text:(my)]\\n [Time: (331.98, 332.52) Text:(calculations.)]\\n [Time: (332.76, 332.92) Text:(In)]\\n [Time: (332.92, 333.04) Text:(a)]\\n [Time: (333.04, 333.32) Text:(shocking)]\\n [Time: (333.32, 333.82) Text:(comeback,)]\\n [Time: (334.06, 334.54) Text:(Alcaras)]\\n [Time: (334.54, 334.8) Text:(won)]\\n [Time: (334.8, 334.94) Text:(the)]\\n [Time: (334.94, 335.16) Text:(match,)]\\n [Time: (335.18, 335.58) Text:(which)]\\n [Time: (335.58, 335.72) Text:(by)]\\n [Time: (335.72, 335.8) Text:(the)]\\n [Time: (335.8, 335.96) Text:(way,)]\\n [Time: (336.14, 336.16) Text:(I)]\\n [Time: (336.16, 336.4) Text:(watched)]\\n [Time: (336.4, 336.66) Text:(life)]\\n [Time: (336.66, 337.0) Text:(anyways)]\\n [Time: (337.0, 337.34) Text:(really)]\\n [Time: (337.34, 337.5) Text:(cool.)]\\n [Time: (337.7, 337.92) Text:(And)]\\n [Time: (337.92, 338.12) Text:(since)]\\n [Time: (338.12, 338.34) Text:(he)]\\n [Time: (338.34, 338.5) Text:(won,)]\\n [Time: (338.72, 338.88) Text:(his)]\\n [Time: (338.88, 339.14) Text:(rating)]\\n [Time: (339.14, 339.4) Text:(has)]\\n [Time: (339.4, 339.54) Text:(to)]\\n [Time: (339.54, 339.66) Text:(be)]\\n [Time: (339.66, 339.86) Text:(updated.)]\\n [Time: (339.86, 340.66) Text:(So)]\\n [Time: (340.66, 340.86) Text:(we)]\\n [Time: (340.86, 341.1) Text:(take)]\\n [Time: (341.1, 341.46) Text:(this)]\\n [Time: (341.46, 341.92) Text:(handy)]\\n [Time: (341.92, 342.28) Text:(little)]\\n [Time: (342.28, 342.64) Text:(formula)]\\n [Time: (342.64, 342.98) Text:(and)]\\n [Time: (342.98, 343.34) Text:(calculate)]\\n [Time: (343.34, 343.66) Text:(his)]\\n [Time: (343.66, 343.9) Text:(new)]\\n [Time: (343.9, 344.22) Text:(rating.)]\\n [Time: (344.42, 344.7) Text:(Turns)]\\n [Time: (344.7, 345.02) Text:(out)]\\n [Time: (345.02, 345.56) Text:(Alcaras)]\\n [Time: (345.56, 345.79) Text:(gained)]\\n [Time: (345.79, 346.16) Text:(about)]\\n [Time: (346.16, 346.52) Text:(14)]\\n [Time: (346.52, 346.94) Text:(points)]\\n [Time: (346.94, 347.22) Text:(and)]\\n [Time: (347.22, 347.7) Text:(Jogovic)]\\n [Time: (347.7, 348.0) Text:(lost)]\\n [Time: (348.0, 348.5) Text:(about)]\\n [Time: (348.5, 348.82) Text:(14)]\\n [Time: (348.82, 349.28) Text:(points.)]\\n [Time: (349.62, 349.64) Text:(So)]\\n [Time: (349.64, 349.98) Text:(it's)]\\n [Time: (349.98, 350.16) Text:(pretty)]\\n [Time: (350.16, 350.42) Text:(easy.)]\\n [Time: (350.44, 350.88) Text:(Actually,)]\\n [Time: (351.0, 351.26) Text:(according)]\\n [Time: (351.26, 351.44) Text:(to)]\\n [Time: (351.44, 351.64) Text:(my)]\\n [Time: (351.64, 352.04) Text:(tennis)]\\n [Time: (352.04, 352.46) Text:(ELO)]\\n [Time: (352.46, 352.92) Text:(rankings,)]\\n [Time: (353.16, 353.24) Text:(the)]\\n [Time: (353.24, 353.5) Text:(current)]\\n [Time: (353.5, 353.78) Text:(bias)]\\n [Time: (353.78, 354.06) Text:(player)]\\n [Time: (354.06, 354.18) Text:(in)]\\n [Time: (354.18, 354.36) Text:(the)]\\n [Time: (354.36, 354.7) Text:(world)]\\n [Time: (354.7, 354.98) Text:(is)]\\n [Time: (354.98, 355.42) Text:(Janice)]\\n [Time: (355.42, 355.74) Text:(Sinner,)]\\n [Time: (355.88, 356.08) Text:(who)]\\n [Time: (356.08, 356.32) Text:(just)]\\n [Time: (356.32, 356.48) Text:(won)]\\n [Time: (356.48, 356.59) Text:(the)]\\n [Time: (356.59, 356.96) Text:(Australian)]\\n [Time: (356.96, 357.36) Text:(Open,)]\\n [Time: (357.58, 357.82) Text:(followed)]\\n [Time: (357.82, 358.04) Text:(by)]\\n [Time: (358.04, 358.36) Text:(Nobac)]\\n [Time: (358.36, 358.88) Text:(Jogovic)]\\n [Time: (358.88, 359.12) Text:(and)]\\n [Time: (359.12, 359.48) Text:(Carlos)]\\n [Time: (359.48, 360.02) Text:(Alcarath.)]\\n [Time: (360.2, 360.38) Text:(And)]\\n [Time: (360.38, 360.72) Text:(here's)]\\n [Time: (360.72, 360.84) Text:(how)]\\n [Time: (360.84, 361.06) Text:(the)]\\n [Time: (361.06, 361.44) Text:(ELO)]\\n [Time: (361.44, 361.62) Text:(has)]\\n [Time: (361.64, 361.96) Text:(evolved)]\\n [Time: (361.96, 362.18) Text:(over)]\\n [Time: (362.18, 362.44) Text:(time.)]\\n [Time: (362.68, 362.98) Text:(This)]\\n [Time: (362.98, 363.52) Text:(represents)]\\n [Time: (363.52, 363.9) Text:(their)]\\n [Time: (363.9, 364.26) Text:(overall)]\\n [Time: (364.26, 364.78) Text:(ELO,)]\\n [Time: (365.12, 365.16) Text:(but)]\\n [Time: (365.16, 365.42) Text:(in)]\\n [Time: (365.42, 365.84) Text:(tennis,)]\\n [Time: (366.12, 366.2) Text:(the)]\\n [Time: (366.2, 366.52) Text:(surface)]\\n [Time: (366.52, 366.86) Text:(you're)]\\n [Time: (366.86, 366.94) Text:(playing)]\\n [Time: (366.94, 367.48) Text:(with)]\\n [Time: (367.48, 367.8) Text:(really)]\\n [Time: (367.8, 368.32) Text:(matters.)]\\n [Time: (368.52, 368.78) Text:(It's)]\\n [Time: (368.78, 369.04) Text:(really)]\\n [Time: (369.04, 369.4) Text:(different)]\\n [Time: (369.4, 369.7) Text:(playing)]\\n [Time: (369.7, 370.12) Text:(tennis)]\\n [Time: (370.12, 370.44) Text:(in)]\\n [Time: (370.44, 370.8) Text:(clay,)]\\n [Time: (371.16, 371.44) Text:(grass)]\\n [Time: (371.44, 371.72) Text:(or)]\\n [Time: (371.72, 372.06) Text:(hard)]\\n [Time: (372.06, 372.48) Text:(surfaces.)]\\n [Time: (372.78, 373.04) Text:(So)]\\n [Time: (373.04, 373.23) Text:(I)]\\n [Time: (373.23, 373.82) Text:(also)]\\n [Time: (373.82, 374.36) Text:(implemented)]\\n [Time: (374.36, 374.96) Text:(surface)]\\n [Time: (374.96, 375.6) Text:(specific)]\\n [Time: (375.6, 376.16) Text:(ELO.)]\\n [Time: (376.26, 376.4) Text:(For)]\\n [Time: (376.4, 376.72) Text:(example,)]\\n [Time: (376.94, 377.52) Text:(Drafanaval)]\\n [Time: (377.52, 377.76) Text:(is)]\\n [Time: (377.76, 378.06) Text:(known)]\\n [Time: (378.06, 378.28) Text:(as)]\\n [Time: (378.28, 378.48) Text:(the)]\\n [Time: (378.48, 378.66) Text:(King)]\\n [Time: (378.66, 378.84) Text:(of)]\\n [Time: (378.84, 379.1) Text:(Clay.)]\\n [Time: (379.24, 379.46) Text:(His)]\\n [Time: (379.46, 379.72) Text:(one)]\\n [Time: (379.72, 380.1) Text:(14)]\\n [Time: (380.1, 380.46) Text:(French)]\\n [Time: (380.46, 380.92) Text:(opens)]\\n [Time: (380.92, 381.22) Text:(and)]\\n [Time: (381.22, 381.46) Text:(has)]\\n [Time: (381.46, 381.64) Text:(a)]\\n [Time: (381.64, 382.38) Text:(112)]\\n [Time: (382.38, 383.04) Text:(win)]\\n [Time: (383.04, 383.36) Text:(versus)]\\n [Time: (383.36, 383.68) Text:(four)]\\n [Time: (383.68, 384.06) Text:(losses)]\\n [Time: (384.06, 384.56) Text:(record)]\\n [Time: (384.56, 384.88) Text:(at)]\\n [Time: (384.88, 384.98) Text:(the)]\\n [Time: (384.98, 385.16) Text:(event.)]\\n [Time: (385.3, 385.46) Text:(The)]\\n [Time: (385.46, 385.68) Text:(guy)]\\n [Time: (385.68, 385.87) Text:(is)]\\n [Time: (385.87, 385.89) Text:(a)]\\n [Time: (385.89, 386.26) Text:(beast.)]\\n [Time: (386.58, 386.78) Text:(And)]\\n [Time: (386.78, 386.88) Text:(as)]\\n [Time: (386.88, 387.0) Text:(you)]\\n [Time: (387.0, 387.24) Text:(can)]\\n [Time: (387.24, 387.38) Text:(see,)]\\n [Time: (387.66, 387.7) Text:(his)]\\n [Time: (387.7, 388.08) Text:(clay)]\\n [Time: (388.08, 388.48) Text:(ELO)]\\n [Time: (388.48, 388.8) Text:(is)]\\n [Time: (388.8, 389.38) Text:(really,)]\\n [Time: (389.38, 389.84) Text:(really)]\\n [Time: (389.84, 390.24) Text:(good.)]\\n [Time: (390.42, 390.56) Text:(In)]\\n [Time: (390.56, 390.72) Text:(fact,)]\\n [Time: (390.84, 391.12) Text:(it's)]\\n [Time: (391.12, 391.26) Text:(the)]\\n [Time: (391.26, 391.52) Text:(highest)]\\n [Time: (391.54, 392.06) Text:(app)]\\n [Time: (392.06, 392.34) Text:(seen.)]\\n [Time: (392.64, 392.84) Text:(As)]\\n [Time: (392.84, 393.06) Text:(I)]\\n [Time: (393.06, 393.12) Text:(find)]\\n [Time: (393.12, 393.26) Text:(an)]\\n [Time: (393.26, 393.7) Text:(example,)]\\n [Time: (393.94, 394.18) Text:(here's)]\\n [Time: (394.18, 394.34) Text:(how)]\\n [Time: (394.34, 394.74) Text:(Carlos)]\\n [Time: (394.74, 395.4) Text:(Alcarath,)]\\n [Time: (395.48, 395.94) Text:(grasses)]\\n [Time: (395.94, 396.5) Text:(ELO)]\\n [Time: (396.5, 396.76) Text:(has)]\\n [Time: (396.76, 397.18) Text:(changed)]\\n [Time: (397.18, 397.52) Text:(after)]\\n [Time: (397.52, 397.86) Text:(winning)]\\n [Time: (398.0, 398.22) Text:(back)]\\n [Time: (398.22, 398.36) Text:(to)]\\n [Time: (398.36, 398.66) Text:(back,)]\\n [Time: (398.8, 399.24) Text:(win-meldon)]\\n [Time: (399.24, 399.62) Text:(titles)]\\n [Time: (399.62, 399.9) Text:(in)]\\n [Time: (399.9, 400.44) Text:(2023)]\\n [Time: (400.44, 400.96) Text:(and)]\\n [Time: (400.96, 401.56) Text:(2024.)]\\n [Time: (401.82, 402.04) Text:(And)]\\n [Time: (402.04, 402.32) Text:(tennis)]\\n [Time: (402.32, 402.72) Text:(ELO)]\\n [Time: (402.72, 402.96) Text:(turns)]\\n [Time: (402.96, 403.16) Text:(out)]\\n [Time: (403.16, 403.3) Text:(to)]\\n [Time: (403.3, 403.46) Text:(be)]\\n [Time: (403.46, 403.88) Text:(quite)]\\n [Time: (403.88, 404.16) Text:(good)]\\n [Time: (404.16, 404.4) Text:(at)]\\n [Time: (404.4, 404.8) Text:(predicting)]\\n [Time: (404.86, 405.22) Text:(who)]\\n [Time: (405.22, 405.4) Text:(will)]\\n [Time: (405.4, 405.62) Text:(win.)]\\n [Time: (405.8, 406.04) Text:(So)]\\n [Time: (406.04, 406.44) Text:(let's)]\\n [Time: (406.44, 406.7) Text:(take)]\\n [Time: (406.7, 407.18) Text:(all)]\\n [Time: (407.18, 407.52) Text:(this)]\\n [Time: (407.52, 407.86) Text:(data)]\\n [Time: (407.86, 408.28) Text:(and)]\\n [Time: (408.28, 408.44) Text:(fit)]\\n [Time: (408.44, 408.88) Text:(it)]\\n [Time: (408.88, 409.06) Text:(into)]\\n [Time: (409.06, 409.2) Text:(our)]\\n [Time: (409.2, 409.5) Text:(decision)]\\n [Time: (409.5, 409.76) Text:(tree)]\\n [Time: (409.76, 410.08) Text:(to)]\\n [Time: (410.08, 410.32) Text:(see)]\\n [Time: (410.32, 410.58) Text:(how)]\\n [Time: (410.58, 410.92) Text:(well)]\\n [Time: (411.02, 411.24) Text:(it)]\\n [Time: (411.24, 411.68) Text:(classifies)]\\n [Time: (411.68, 412.1) Text:(winners.)]\\n [Time: (412.36, 412.54) Text:(And)]\\n [Time: (412.54, 412.68) Text:(while)]\\n [Time: (412.68, 412.88) Text:(my)]\\n [Time: (412.88, 413.16) Text:(model)]\\n [Time: (413.16, 413.34) Text:(is)]\\n [Time: (413.34, 413.62) Text:(training,)]\\n [Time: (413.96, 414.0) Text:(I)]\\n [Time: (414.0, 414.18) Text:(want)]\\n [Time: (414.18, 414.38) Text:(you)]\\n [Time: (414.38, 414.4) Text:(to)]\\n [Time: (414.4, 414.62) Text:(thank)]\\n [Time: (414.62, 415.02) Text:(Brilliant)]\\n [Time: (415.02, 415.24) Text:(for)]\\n [Time: (415.24, 415.72) Text:(sponsoring)]\\n [Time: (415.78, 416.02) Text:(this)]\\n [Time: (416.02, 416.32) Text:(video.)]\\n [Time: (416.46, 416.86) Text:(Brilliant)]\\n [Time: (416.86, 417.12) Text:(is)]\\n [Time: (417.12, 417.4) Text:(an)]\\n [Time: (417.4, 417.76) Text:(online)]\\n [Time: (417.76, 418.1) Text:(learning)]\\n [Time: (418.1, 418.58) Text:(platform)]\\n [Time: (418.58, 418.9) Text:(for)]\\n [Time: (418.9, 419.26) Text:(computer)]\\n [Time: (419.26, 419.72) Text:(science,)]\\n [Time: (419.78, 420.32) Text:(science)]\\n [Time: (420.32, 420.56) Text:(and)]\\n [Time: (420.56, 420.92) Text:(maths.)]\\n [Time: (421.04, 421.22) Text:(They)]\\n [Time: (421.22, 421.52) Text:(have)]\\n [Time: (421.52, 421.78) Text:(great)]\\n [Time: (421.78, 422.26) Text:(courses)]\\n [Time: (422.26, 422.66) Text:(on)]\\n [Time: (422.66, 423.1) Text:(everything)]\\n [Time: (423.1, 423.4) Text:(from)]\\n [Time: (423.4, 423.86) Text:(calculus)]\\n [Time: (423.86, 424.22) Text:(and)]\\n [Time: (424.22, 424.46) Text:(linear)]\\n [Time: (424.46, 424.96) Text:(algebra)]\\n [Time: (424.96, 425.38) Text:(all)]\\n [Time: (425.38, 425.52) Text:(the)]\\n [Time: (425.52, 425.72) Text:(way)]\\n [Time: (425.72, 425.96) Text:(up)]\\n [Time: (425.96, 426.16) Text:(to)]\\n [Time: (426.16, 426.42) Text:(neural)]\\n [Time: (426.42, 426.92) Text:(networks.)]\\n [Time: (427.22, 427.48) Text:(In)]\\n [Time: (427.48, 427.7) Text:(fact,)]\\n [Time: (427.86, 427.92) Text:(I)]\\n [Time: (427.92, 428.1) Text:(have)]\\n [Time: (428.1, 428.34) Text:(done)]\\n [Time: (428.34, 428.46) Text:(a)]\\n [Time: (428.46, 428.62) Text:(lot)]\\n [Time: (428.62, 428.76) Text:(of)]\\n [Time: (428.76, 428.88) Text:(stuff)]\\n [Time: (428.88, 429.1) Text:(behind)]\\n [Time: (429.1, 429.3) Text:(the)]\\n [Time: (429.3, 429.46) Text:(scenes)]\\n [Time: (429.46, 429.66) Text:(that)]\\n [Time: (429.66, 429.74) Text:(I)]\\n [Time: (429.74, 430.1) Text:(haven't)]\\n [Time: (430.1, 430.22) Text:(really)]\\n [Time: (430.22, 430.38) Text:(shown)]\\n [Time: (430.38, 430.54) Text:(in)]\\n [Time: (430.54, 430.64) Text:(the)]\\n [Time: (430.64, 430.88) Text:(video,)]\\n [Time: (431.1, 431.34) Text:(like)]\\n [Time: (431.34, 431.7) Text:(principal)]\\n [Time: (431.7, 432.2) Text:(component)]\\n [Time: (432.2, 432.76) Text:(analysis,)]\\n [Time: (433.1, 433.28) Text:(linear)]\\n [Time: (433.28, 433.78) Text:(regression)]\\n [Time: (433.78, 434.16) Text:(and)]\\n [Time: (434.16, 434.22) Text:(a)]\\n [Time: (434.22, 434.46) Text:(bunch)]\\n [Time: (434.46, 434.7) Text:(more.)]\\n [Time: (435.02, 435.2) Text:(And)]\\n [Time: (435.2, 435.38) Text:(while)]\\n [Time: (435.38, 435.68) Text:(I)]\\n [Time: (435.68, 436.02) Text:(won't)]\\n [Time: (436.02, 436.08) Text:(have)]\\n [Time: (436.08, 436.3) Text:(time)]\\n [Time: (436.3, 436.42) Text:(to)]\\n [Time: (436.42, 436.7) Text:(explain)]\\n [Time: (436.7, 437.04) Text:(it,)]\\n [Time: (437.08, 437.34) Text:(Brilliant)]\\n [Time: (437.34, 437.56) Text:(has)]\\n [Time: (437.56, 437.8) Text:(some)]\\n [Time: (437.8, 438.54) Text:(fantastic)]\\n [Time: (438.54, 439.26) Text:(introductory)]\\n [Time: (439.26, 439.8) Text:(courses)]\\n [Time: (439.8, 440.22) Text:(on)]\\n [Time: (440.22, 440.46) Text:(data)]\\n [Time: (440.46, 440.96) Text:(analysis)]\\n [Time: (440.96, 441.32) Text:(and)]\\n [Time: (441.32, 441.84) Text:(probability,)]\\n [Time: (442.12, 442.42) Text:(where)]\\n [Time: (442.42, 442.72) Text:(you)]\\n [Time: (442.72, 443.02) Text:(learn)]\\n [Time: (443.02, 443.24) Text:(by)]\\n [Time: (443.24, 443.9) Text:(experimenting)]\\n [Time: (443.9, 444.38) Text:(with)]\\n [Time: (444.38, 444.84) Text:(hands-on)]\\n [Time: (444.84, 445.32) Text:(examples.)]\\n [Time: (445.5, 445.72) Text:(They)]\\n [Time: (445.72, 446.0) Text:(make)]\\n [Time: (446.0, 446.42) Text:(learning)]\\n [Time: (446.42, 446.86) Text:(fun)]\\n [Time: (446.86, 447.16) Text:(by)]\\n [Time: (447.16, 447.52) Text:(giving)]\\n [Time: (447.52, 447.76) Text:(you)]\\n [Time: (447.76, 448.18) Text:(puzzles)]\\n [Time: (448.44, 448.76) Text:(and)]\\n [Time: (448.76, 448.94) Text:(little)]\\n [Time: (448.94, 449.24) Text:(games)]\\n [Time: (449.24, 449.48) Text:(to)]\\n [Time: (449.48, 449.68) Text:(test)]\\n [Time: (449.68, 449.9) Text:(your)]\\n [Time: (449.9, 450.32) Text:(understanding.)]\\n [Time: (450.56, 450.74) Text:(They)]\\n [Time: (450.74, 451.08) Text:(even)]\\n [Time: (451.08, 451.3) Text:(have)]\\n [Time: (451.3, 451.76) Text:(courses)]\\n [Time: (451.76, 452.1) Text:(on)]\\n [Time: (452.1, 452.52) Text:(search)]\\n [Time: (452.52, 453.08) Text:(engines,)]\\n [Time: (453.24, 453.88) Text:(cryptocurrencies,)]\\n [Time: (454.2, 454.44) Text:(quantum)]\\n [Time: (454.44, 454.9) Text:(computing,)]\\n [Time: (455.22, 455.38) Text:(how)]\\n [Time: (455.38, 455.76) Text:(AI)]\\n [Time: (455.76, 456.12) Text:(works)]\\n [Time: (456.12, 456.52) Text:(and)]\\n [Time: (456.52, 456.86) Text:(loads)]\\n [Time: (456.86, 457.2) Text:(and)]\\n [Time: (457.2, 457.5) Text:(loads)]\\n [Time: (457.5, 457.84) Text:(of)]\\n [Time: (457.84, 458.28) Text:(other)]\\n [Time: (458.28, 458.96) Text:(fascinating)]\\n [Time: (458.96, 459.46) Text:(things.)]\\n [Time: (459.66, 460.08) Text:(So)]\\n [Time: (460.08, 460.26) Text:(if)]\\n [Time: (460.26, 460.38) Text:(you)]\\n [Time: (460.38, 460.54) Text:(want)]\\n [Time: (460.54, 460.76) Text:(to)]\\n [Time: (460.76, 461.1) Text:(support)]\\n [Time: (461.1, 461.36) Text:(this)]\\n [Time: (461.36, 461.7) Text:(channel)]\\n [Time: (461.7, 462.0) Text:(and)]\\n [Time: (462.0, 462.4) Text:(explore)]\\n [Time: (462.4, 463.06) Text:(exciting)]\\n [Time: (463.06, 463.42) Text:(and)]\\n [Time: (463.42, 463.88) Text:(interesting)]\\n [Time: (463.88, 464.4) Text:(topics,)]\\n [Time: (464.58, 464.8) Text:(click)]\\n [Time: (464.8, 464.98) Text:(the)]\\n [Time: (464.98, 465.22) Text:(link)]\\n [Time: (465.22, 465.4) Text:(in)]\\n [Time: (465.4, 465.44) Text:(the)]\\n [Time: (465.44, 465.88) Text:(description)]\\n [Time: (465.88, 466.2) Text:(and)]\\n [Time: (466.2, 466.4) Text:(use)]\\n [Time: (466.4, 466.7) Text:(my)]\\n [Time: (466.7, 466.94) Text:(code)]\\n [Time: (466.94, 467.7) Text:(greencode)]\\n [Time: (467.7, 467.96) Text:(for)]\\n [Time: (467.96, 468.18) Text:(a)]\\n [Time: (468.18, 468.78) Text:(30-day)]\\n [Time: (468.78, 469.08) Text:(free)]\\n [Time: (469.08, 469.28) Text:(trial)]\\n [Time: (469.28, 469.56) Text:(and)]\\n [Time: (469.56, 469.74) Text:(a)]\\n [Time: (469.74, 469.92) Text:(20%)]\\n [Time: (470.3, 470.76) Text:(discount)]\\n [Time: (470.76, 471.12) Text:(on)]\\n [Time: (471.12, 471.3) Text:(the)]\\n [Time: (471.3, 471.68) Text:(annual)]\\n [Time: (471.68, 472.08) Text:(premium)]\\n [Time: (472.08, 472.66) Text:(subscription.)]\\n [Time: (473.04, 473.24) Text:(Seriously,)]\\n [Time: (473.44, 473.54) Text:(they're)]\\n [Time: (473.54, 473.96) Text:(awesome.)]\\n [Time: (474.32, 474.34) Text:(So)]\\n [Time: (474.34, 474.62) Text:(go)]\\n [Time: (474.62, 474.82) Text:(check)]\\n [Time: (474.82, 475.0) Text:(them)]\\n [Time: (475.0, 475.18) Text:(out.)]\\n [Time: (475.22, 475.5) Text:(Ooh,)]\\n [Time: (475.72, 475.92) Text:(okay,)]\\n [Time: (476.1, 476.16) Text:(our)]\\n [Time: (476.16, 476.52) Text:(decision)]\\n [Time: (476.52, 476.86) Text:(tree)]\\n [Time: (476.86, 477.16) Text:(is)]\\n [Time: (477.16, 477.28) Text:(finished)]\\n [Time: (477.28, 477.6) Text:(training.)]\\n [Time: (477.86, 478.12) Text:(And)]\\n [Time: (478.12, 478.3) Text:(I)]\\n [Time: (478.3, 478.44) Text:(have)]\\n [Time: (478.44, 478.64) Text:(some)]\\n [Time: (478.64, 478.86) Text:(good)]\\n [Time: (478.86, 479.18) Text:(news)]\\n [Time: (479.18, 479.46) Text:(and)]\\n [Time: (479.46, 479.7) Text:(some)]\\n [Time: (479.7, 479.84) Text:(bad)]\\n [Time: (479.84, 480.14) Text:(news.)]\\n [Time: (480.3, 480.54) Text:(Good)]\\n [Time: (480.54, 480.84) Text:(news)]\\n [Time: (480.84, 481.1) Text:(is)]\\n [Time: (481.1, 481.32) Text:(that)]\\n [Time: (481.32, 481.52) Text:(it)]\\n [Time: (481.52, 481.64) Text:(gave)]\\n [Time: (481.64, 481.94) Text:(us)]\\n [Time: (481.94, 482.08) Text:(a)]\\n [Time: (482.08, 482.3) Text:(pretty)]\\n [Time: (482.3, 482.62) Text:(cool)]\\n [Time: (482.62, 482.92) Text:(looking)]\\n [Time: (482.92, 483.38) Text:(decision)]\\n [Time: (483.38, 483.68) Text:(tree.)]\\n [Time: (483.84, 484.1) Text:(Bad)]\\n [Time: (484.1, 484.4) Text:(news)]\\n [Time: (484.4, 484.74) Text:(is)]\\n [Time: (484.74, 485.0) Text:(that)]\\n [Time: (485.0, 485.2) Text:(my)]\\n [Time: (485.2, 485.82) Text:(implementation)]\\n [Time: (486.54, 486.56) Text:(was)]\\n [Time: (486.56, 486.88) Text:(really)]\\n [Time: (486.88, 487.36) Text:(slow,)]\\n [Time: (487.74, 487.76) Text:(like)]\\n [Time: (487.76, 488.48) Text:(painfully)]\\n [Time: (488.48, 488.82) Text:(slow.)]\\n [Time: (489.22, 489.34) Text:(So)]\\n [Time: (489.34, 489.42) Text:(I)]\\n [Time: (489.42, 489.6) Text:(ended)]\\n [Time: (489.6, 489.76) Text:(up)]\\n [Time: (489.76, 489.98) Text:(having)]\\n [Time: (489.98, 490.14) Text:(to)]\\n [Time: (490.14, 490.36) Text:(use)]\\n [Time: (490.36, 490.76) Text:(SK)]\\n [Time: (490.76, 491.26) Text:(learns)]\\n [Time: (491.26, 491.82) Text:(version,)]\\n [Time: (492.04, 492.32) Text:(but)]\\n [Time: (492.32, 492.58) Text:(for)]\\n [Time: (492.58, 492.78) Text:(all)]\\n [Time: (492.78, 492.9) Text:(the)]\\n [Time: (492.9, 493.14) Text:(haters)]\\n [Time: (493.14, 493.4) Text:(out)]\\n [Time: (493.4, 493.54) Text:(there,)]\\n [Time: (493.66, 493.72) Text:(my)]\\n [Time: (493.72, 494.14) Text:(code)]\\n [Time: (494.14, 494.44) Text:(works,)]\\n [Time: (494.52, 494.7) Text:(okay?)]\\n [Time: (494.88, 494.96) Text:(I)]\\n [Time: (494.96, 495.22) Text:(tested)]\\n [Time: (495.22, 495.48) Text:(it)]\\n [Time: (495.48, 495.62) Text:(on)]\\n [Time: (495.62, 495.9) Text:(smaller)]\\n [Time: (495.9, 496.16) Text:(data)]\\n [Time: (496.16, 496.42) Text:(sets)]\\n [Time: (496.42, 496.62) Text:(and)]\\n [Time: (496.62, 496.85) Text:(it)]\\n [Time: (496.85, 497.14) Text:(works)]\\n [Time: (497.14, 497.48) Text:(just)]\\n [Time: (497.48, 497.66) Text:(as)]\\n [Time: (497.66, 497.9) Text:(fine.)]\\n [Time: (498.08, 498.46) Text:(It's)]\\n [Time: (498.46, 498.48) Text:(just,)]\\n [Time: (498.48, 498.78) Text:(it's)]\\n [Time: (498.78, 498.92) Text:(not)]\\n [Time: (498.92, 499.14) Text:(ready)]\\n [Time: (499.14, 499.32) Text:(to)]\\n [Time: (499.32, 499.62) Text:(handle)]\\n [Time: (499.62, 501.02) Text:(95,000)]\\n [Time: (501.02, 501.28) Text:(tennis)]\\n [Time: (501.28, 501.66) Text:(matches.)]\\n [Time: (501.84, 502.1) Text:(But)]\\n [Time: (502.1, 502.56) Text:(anyway,)]\\n [Time: (502.7, 503.1) Text:(we're)]\\n [Time: (503.1, 503.12) Text:(using)]\\n [Time: (503.12, 503.4) Text:(that)]\\n [Time: (503.4, 503.98) Text:(classifier)]\\n [Time: (503.98, 504.26) Text:(out)]\\n [Time: (504.26, 504.36) Text:(of)]\\n [Time: (504.36, 504.52) Text:(the)]\\n [Time: (504.52, 504.7) Text:(box.)]\\n [Time: (504.78, 504.94) Text:(We)]\\n [Time: (504.94, 505.18) Text:(get)]\\n [Time: (505.18, 505.96) Text:(74%)]\\n [Time: (506.52, 507.02) Text:(accuracy,)]\\n [Time: (507.34, 507.4) Text:(which)]\\n [Time: (507.4, 507.7) Text:(sounds)]\\n [Time: (507.7, 507.98) Text:(really)]\\n [Time: (507.98, 508.52) Text:(promising)]\\n [Time: (508.86, 509.08) Text:(until)]\\n [Time: (509.08, 509.4) Text:(you)]\\n [Time: (509.4, 509.88) Text:(realize)]\\n [Time: (509.88, 510.4) Text:(that)]\\n [Time: (510.4, 510.7) Text:(simply)]\\n [Time: (510.7, 511.14) Text:(predicting)]\\n [Time: (511.14, 511.62) Text:(based)]\\n [Time: (511.62, 511.9) Text:(on)]\\n [Time: (511.9, 512.18) Text:(ILO)]\\n [Time: (512.18, 512.68) Text:(alone)]\\n [Time: (512.68, 513.08) Text:(gives)]\\n [Time: (513.08, 513.36) Text:(you)]\\n [Time: (513.36, 513.88) Text:(72%)]\\n [Time: (514.28, 514.76) Text:(accuracy.)]\\n [Time: (514.98, 515.14) Text:(So)]\\n [Time: (515.14, 515.28) Text:(yeah,)]\\n [Time: (515.34, 515.48) Text:(we)]\\n [Time: (515.48, 515.62) Text:(can)]\\n [Time: (515.62, 515.78) Text:(do)]\\n [Time: (515.78, 515.96) Text:(better.)]\\n [Time: (516.14, 516.24) Text:(To)]\\n [Time: (516.24, 516.42) Text:(take)]\\n [Time: (516.42, 516.64) Text:(things)]\\n [Time: (516.64, 516.82) Text:(to)]\\n [Time: (516.82, 516.92) Text:(the)]\\n [Time: (516.92, 517.16) Text:(next)]\\n [Time: (517.16, 517.46) Text:(level,)]\\n [Time: (517.72, 517.74) Text:(we)]\\n [Time: (517.74, 517.98) Text:(need)]\\n [Time: (517.98, 518.38) Text:(random)]\\n [Time: (518.38, 519.02) Text:(forests.)]\\n [Time: (519.24, 519.54) Text:(As)]\\n [Time: (519.54, 519.8) Text:(single)]\\n [Time: (519.8, 520.18) Text:(decision)]\\n [Time: (520.18, 520.5) Text:(tree,)]\\n [Time: (520.5, 520.8) Text:(tend)]\\n [Time: (520.8, 521.04) Text:(to)]\\n [Time: (521.04, 521.32) Text:(have)]\\n [Time: (521.32, 521.6) Text:(high)]\\n [Time: (521.6, 522.0) Text:(variance.)]\\n [Time: (522.22, 522.34) Text:(So)]\\n [Time: (522.34, 522.54) Text:(it's)]\\n [Time: (522.54, 522.8) Text:(quite)]\\n [Time: (522.8, 523.26) Text:(sensitive)]\\n [Time: (523.26, 523.54) Text:(to)]\\n [Time: (523.54, 523.78) Text:(the)]\\n [Time: (523.78, 524.1) Text:(specific)]\\n [Time: (524.1, 524.44) Text:(data)]\\n [Time: (524.44, 524.8) Text:(it's)]\\n [Time: (524.8, 525.02) Text:(trained)]\\n [Time: (525.02, 525.24) Text:(on.)]\\n [Time: (525.34, 525.68) Text:(But)]\\n [Time: (525.68, 525.84) Text:(if)]\\n [Time: (525.84, 526.06) Text:(we)]\\n [Time: (526.06, 526.32) Text:(create)]\\n [Time: (526.32, 526.76) Text:(multiple)]\\n [Time: (526.76, 527.18) Text:(trees,)]\\n [Time: (527.44, 527.56) Text:(it's)]\\n [Time: (527.56, 527.84) Text:(making)]\\n [Time: (527.84, 528.16) Text:(its)]\\n [Time: (528.16, 528.32) Text:(own)]\\n [Time: (528.32, 528.68) Text:(prediction.)]\\n [Time: (528.86, 529.04) Text:(We)]\\n [Time: (529.04, 529.22) Text:(can)]\\n [Time: (529.22, 529.62) Text:(combine)]\\n [Time: (529.62, 529.8) Text:(the)]\\n [Time: (529.8, 530.16) Text:(results)]\\n [Time: (530.28, 530.46) Text:(through)]\\n [Time: (530.46, 530.58) Text:(a)]\\n [Time: (530.58, 530.92) Text:(majority)]\\n [Time: (530.92, 531.22) Text:(boat)]\\n [Time: (531.22, 531.48) Text:(and)]\\n [Time: (531.48, 531.68) Text:(get)]\\n [Time: (531.68, 531.88) Text:(a)]\\n [Time: (531.88, 532.1) Text:(more)]\\n [Time: (532.1, 532.5) Text:(stable)]\\n [Time: (532.5, 532.74) Text:(and)]\\n [Time: (532.74, 533.16) Text:(accurate)]\\n [Time: (533.16, 533.5) Text:(model.)]\\n [Time: (533.66, 533.84) Text:(Now,)]\\n [Time: (534.02, 534.24) Text:(building)]\\n [Time: (534.24, 534.44) Text:(a)]\\n [Time: (534.44, 534.74) Text:(decision)]\\n [Time: (534.74, 534.98) Text:(tree)]\\n [Time: (534.98, 535.56) Text:(is)]\\n [Time: (535.56, 535.74) Text:(the)]\\n [Time: (535.74, 536.36) Text:(terministic.)]\\n [Time: (536.48, 536.72) Text:(That)]\\n [Time: (536.72, 536.94) Text:(is,)]\\n [Time: (537.08, 537.2) Text:(if)]\\n [Time: (537.2, 537.44) Text:(the)]\\n [Time: (537.44, 537.8) Text:(input)]\\n [Time: (537.8, 538.14) Text:(stays)]\\n [Time: (538.14, 538.48) Text:(the)]\\n [Time: (538.48, 538.64) Text:(same,)]\\n [Time: (538.84, 538.98) Text:(we'll)]\\n [Time: (538.98, 539.18) Text:(build)]\\n [Time: (539.18, 539.8) Text:(exactly)]\\n [Time: (539.8, 540.06) Text:(the)]\\n [Time: (540.06, 540.34) Text:(same)]\\n [Time: (540.34, 540.54) Text:(tree)]\\n [Time: (540.76, 541.04) Text:(over)]\\n [Time: (541.04, 541.28) Text:(and)]\\n [Time: (541.28, 541.54) Text:(over.)]\\n [Time: (541.7, 541.86) Text:(So)]\\n [Time: (541.86, 542.06) Text:(the)]\\n [Time: (542.06, 542.2) Text:(trick)]\\n [Time: (542.2, 542.44) Text:(to)]\\n [Time: (542.44, 542.82) Text:(build)]\\n [Time: (542.82, 543.2) Text:(around)]\\n [Time: (543.2, 543.42) Text:(the)]\\n [Time: (543.42, 543.74) Text:(forest)]\\n [Time: (543.74, 544.14) Text:(is)]\\n [Time: (544.14, 544.6) Text:(build)]\\n [Time: (544.6, 544.92) Text:(many)]\\n [Time: (544.92, 545.28) Text:(trees)]\\n [Time: (545.28, 545.68) Text:(using)]\\n [Time: (545.68, 546.22) Text:(different)]\\n [Time: (546.28, 546.66) Text:(random)]\\n [Time: (546.66, 547.26) Text:(subsets)]\\n [Time: (547.26, 547.42) Text:(of)]\\n [Time: (547.42, 547.68) Text:(the)]\\n [Time: (547.68, 547.86) Text:(data)]\\n [Time: (547.86, 548.18) Text:(and)]\\n [Time: (548.18, 548.56) Text:(different)]\\n [Time: (548.56, 549.24) Text:(subsets)]\\n [Time: (549.24, 549.4) Text:(of)]\\n [Time: (549.4, 549.64) Text:(the)]\\n [Time: (549.64, 550.24) Text:(bearables.)]\\n [Time: (550.36, 550.62) Text:(This)]\\n [Time: (550.62, 550.9) Text:(way,)]\\n [Time: (550.94, 551.22) Text:(there's)]\\n [Time: (551.22, 551.38) Text:(a)]\\n [Time: (551.38, 551.66) Text:(little)]\\n [Time: (551.66, 551.79) Text:(bit)]\\n [Time: (551.79, 552.02) Text:(of)]\\n [Time: (552.02, 552.28) Text:(more)]\\n [Time: (552.28, 552.84) Text:(variation,)]\\n [Time: (553.0, 553.34) Text:(which)]\\n [Time: (553.34, 553.62) Text:(makes)]\\n [Time: (553.62, 553.88) Text:(the)]\\n [Time: (553.88, 554.16) Text:(model)]\\n [Time: (554.16, 554.46) Text:(more)]\\n [Time: (554.46, 554.78) Text:(robust.)]\\n [Time: (555.02, 555.2) Text:(I)]\\n [Time: (555.2, 555.46) Text:(also)]\\n [Time: (555.46, 555.96) Text:(implemented)]\\n [Time: (555.96, 556.28) Text:(my)]\\n [Time: (556.28, 556.42) Text:(or)]\\n [Time: (556.42, 556.68) Text:(random)]\\n [Time: (556.68, 556.91) Text:(forest)]\\n [Time: (556.91, 557.24) Text:(from)]\\n [Time: (557.24, 557.6) Text:(scratch,)]\\n [Time: (557.78, 558.06) Text:(but)]\\n [Time: (558.06, 558.32) Text:(guess)]\\n [Time: (558.32, 558.48) Text:(what,)]\\n [Time: (558.62, 558.68) Text:(it)]\\n [Time: (558.68, 558.88) Text:(was)]\\n [Time: (558.88, 559.08) Text:(too)]\\n [Time: (559.08, 559.26) Text:(slow)]\\n [Time: (559.26, 559.48) Text:(for)]\\n [Time: (559.48, 559.78) Text:(my)]\\n [Time: (559.78, 560.1) Text:(huge)]\\n [Time: (560.1, 560.4) Text:(data)]\\n [Time: (560.4, 560.6) Text:(set)]\\n [Time: (560.6, 560.88) Text:(again.)]\\n [Time: (561.14, 561.32) Text:(But)]\\n [Time: (561.32, 561.72) Text:(using)]\\n [Time: (561.72, 562.2) Text:(SK)]\\n [Time: (562.2, 562.5) Text:(learn,)]\\n [Time: (562.58, 562.78) Text:(I)]\\n [Time: (562.78, 563.04) Text:(got)]\\n [Time: (563.04, 563.88) Text:(76%)]\\n [Time: (564.56, 564.8) Text:(not)]\\n [Time: (564.8, 565.06) Text:(bad,)]\\n [Time: (565.1, 565.3) Text:(not)]\\n [Time: (565.3, 565.52) Text:(bad.)]\\n [Time: (565.7, 565.76) Text:(We)]\\n [Time: (565.76, 566.04) Text:(can)]\\n [Time: (566.04, 566.44) Text:(even)]\\n [Time: (566.44, 566.94) Text:(visualize)]\\n [Time: (566.94, 567.36) Text:(our)]\\n [Time: (567.36, 567.74) Text:(forest)]\\n [Time: (567.74, 568.2) Text:(and)]\\n [Time: (568.2, 568.52) Text:(it)]\\n [Time: (568.52, 568.8) Text:(looks)]\\n [Time: (568.8, 569.1) Text:(like)]\\n [Time: (569.1, 569.46) Text:(this,)]\\n [Time: (569.5, 569.76) Text:(pretty)]\\n [Time: (569.76, 570.0) Text:(sick,)]\\n [Time: (570.06, 570.22) Text:(right?)]\\n [Time: (570.38, 570.64) Text:(Now,)]\\n [Time: (570.78, 570.84) Text:(at)]\\n [Time: (570.84, 571.06) Text:(this)]\\n [Time: (571.06, 571.38) Text:(point,)]\\n [Time: (571.7, 571.8) Text:(things)]\\n [Time: (571.8, 572.08) Text:(got)]\\n [Time: (572.08, 572.42) Text:(tricky.)]\\n [Time: (572.56, 572.7) Text:(I)]\\n [Time: (572.7, 572.88) Text:(tried)]\\n [Time: (572.88, 573.04) Text:(to)]\\n [Time: (573.04, 573.34) Text:(improve)]\\n [Time: (573.34, 573.58) Text:(my)]\\n [Time: (573.58, 573.86) Text:(model)]\\n [Time: (573.86, 574.16) Text:(by)]\\n [Time: (574.16, 574.42) Text:(running)]\\n [Time: (574.42, 574.68) Text:(a)]\\n [Time: (574.68, 574.86) Text:(grid)]\\n [Time: (574.86, 575.24) Text:(search,)]\\n [Time: (575.34, 575.66) Text:(tweaking)]\\n [Time: (575.66, 575.82) Text:(the)]\\n [Time: (575.82, 576.1) Text:(data)]\\n [Time: (576.1, 576.36) Text:(and)]\\n [Time: (576.36, 577.04) Text:(fine-tuning)]\\n [Time: (577.04, 577.24) Text:(the)]\\n [Time: (577.24, 577.62) Text:(random)]\\n [Time: (577.62, 577.92) Text:(forest)]\\n [Time: (577.92, 578.38) Text:(parameters.)]\\n [Time: (578.94, 578.98) Text:(But)]\\n [Time: (578.98, 579.14) Text:(no)]\\n [Time: (579.14, 579.36) Text:(matter)]\\n [Time: (579.36, 579.52) Text:(what,)]\\n [Time: (579.7, 579.76) Text:(I)]\\n [Time: (579.76, 579.95) Text:(tried,)]\\n [Time: (579.95, 580.28) Text:(I)]\\n [Time: (580.28, 580.52) Text:(got)]\\n [Time: (580.52, 580.8) Text:(stuck)]\\n [Time: (580.8, 581.14) Text:(at)]\\n [Time: (581.14, 582.46) Text:(76-77%)]\\n [Time: (582.86, 583.34) Text:(accuracy.)]\\n [Time: (583.9, 583.92) Text:(So)]\\n [Time: (583.92, 584.22) Text:(I)]\\n [Time: (584.22, 584.52) Text:(decided)]\\n [Time: (584.52, 584.8) Text:(to)]\\n [Time: (584.8, 585.14) Text:(try)]\\n [Time: (585.14, 586.02) Text:(XG)]\\n [Time: (586.02, 586.5) Text:(Boost.)]\\n [Time: (586.82, 587.06) Text:(An)]\\n [Time: (587.06, 587.48) Text:(XG)]\\n [Time: (587.48, 587.68) Text:(Boost)]\\n [Time: (587.68, 588.36) Text:(classifier)]\\n [Time: (588.36, 588.76) Text:(is)]\\n [Time: (588.76, 588.98) Text:(like)]\\n [Time: (588.98, 589.18) Text:(a)]\\n [Time: (589.18, 589.56) Text:(random)]\\n [Time: (589.56, 590.0) Text:(forest)]\\n [Time: (590.0, 590.46) Text:(on)]\\n [Time: (590.46, 590.96) Text:(steroids.)]\\n [Time: (591.04, 591.26) Text:(It)]\\n [Time: (591.26, 591.54) Text:(uses)]\\n [Time: (591.54, 592.04) Text:(boosting)]\\n [Time: (592.04, 592.94) Text:(regularization)]\\n [Time: (592.94, 593.18) Text:(to)]\\n [Time: (593.18, 593.52) Text:(prevent)]\\n [Time: (593.52, 594.24) Text:(overfitting)]\\n [Time: (594.24, 594.68) Text:(and)]\\n [Time: (594.68, 595.0) Text:(it)]\\n [Time: (595.0, 595.2) Text:(keeps)]\\n [Time: (595.3, 595.56) Text:(trees)]\\n [Time: (595.56, 595.86) Text:(from)]\\n [Time: (595.86, 596.18) Text:(growing)]\\n [Time: (596.18, 596.38) Text:(too)]\\n [Time: (596.38, 596.64) Text:(large.)]\\n [Time: (596.88, 597.08) Text:(It's)]\\n [Time: (597.08, 597.18) Text:(kind)]\\n [Time: (597.18, 597.28) Text:(of)]\\n [Time: (597.28, 597.5) Text:(hard)]\\n [Time: (597.5, 597.64) Text:(to)]\\n [Time: (597.64, 597.88) Text:(explain)]\\n [Time: (597.88, 598.04) Text:(in)]\\n [Time: (598.04, 598.18) Text:(this)]\\n [Time: (598.18, 598.42) Text:(video,)]\\n [Time: (598.76, 598.78) Text:(but)]\\n [Time: (598.78, 599.06) Text:(maybe)]\\n [Time: (599.06, 599.26) Text:(if)]\\n [Time: (599.26, 599.38) Text:(you)]\\n [Time: (599.38, 599.7) Text:(like)]\\n [Time: (599.7, 599.87) Text:(the)]\\n [Time: (599.87, 600.26) Text:(video,)]\\n [Time: (600.38, 600.52) Text:(I)]\\n [Time: (600.52, 600.66) Text:(could)]\\n [Time: (600.66, 600.98) Text:(explain)]\\n [Time: (600.98, 601.14) Text:(it)]\\n [Time: (601.14, 601.32) Text:(in)]\\n [Time: (601.32, 601.56) Text:(another)]\\n [Time: (601.56, 601.84) Text:(one.)]\\n [Time: (601.96, 602.22) Text:(But)]\\n [Time: (602.22, 602.54) Text:(you)]\\n [Time: (602.54, 602.72) Text:(know,)]\\n [Time: (602.86, 602.98) Text:(up)]\\n [Time: (602.98, 603.2) Text:(to)]\\n [Time: (603.2, 603.36) Text:(you,)]\\n [Time: (603.52, 604.0) Text:(it's)]\\n [Time: (604.0, 604.24) Text:(right)]\\n [Time: (604.24, 604.44) Text:(there,)]\\n [Time: (604.66, 604.68) Text:(though,)]\\n [Time: (604.82, 604.96) Text:(just)]\\n [Time: (604.96, 605.1) Text:(saying.)]\\n [Time: (605.26, 605.44) Text:(But)]\\n [Time: (605.44, 605.7) Text:(anyway,)]\\n [Time: (605.92, 605.94) Text:(I)]\\n [Time: (605.94, 606.12) Text:(got)]\\n [Time: (606.12, 606.46) Text:(a)]\\n [Time: (606.46, 606.88) Text:(staggering)]\\n [Time: (606.88, 607.68) Text:(85%)]\\n [Time: (608.14, 608.7) Text:(accuracy,)]\\n [Time: (609.12, 609.14) Text:(baby.)]\\n [Time: (609.36, 609.46) Text:(You,)]\\n [Time: (609.92, 610.1) Text:(and)]\\n [Time: (610.1, 610.24) Text:(as)]\\n [Time: (610.24, 610.32) Text:(you)]\\n [Time: (610.32, 610.5) Text:(can)]\\n [Time: (610.5, 610.68) Text:(see,)]\\n [Time: (610.8, 610.96) Text:(the)]\\n [Time: (610.96, 611.24) Text:(most)]\\n [Time: (611.24, 611.84) Text:(important)]\\n [Time: (611.84, 612.38) Text:(features)]\\n [Time: (612.5, 612.74) Text:(a)]\\n [Time: (612.74, 613.22) Text:(recognize)]\\n [Time: (613.22, 613.7) Text:(were)]\\n [Time: (613.7, 614.02) Text:(ILO)]\\n [Time: (614.02, 614.38) Text:(surface)]\\n [Time: (614.38, 614.9) Text:(difference)]\\n [Time: (614.9, 615.26) Text:(and)]\\n [Time: (615.26, 615.56) Text:(total)]\\n [Time: (615.56, 616.12) Text:(ILO,)]\\n [Time: (616.22, 616.5) Text:(which)]\\n [Time: (616.5, 616.64) Text:(is)]\\n [Time: (616.64, 616.86) Text:(pretty)]\\n [Time: (616.86, 617.18) Text:(cool.)]\\n [Time: (617.24, 617.54) Text:(Just)]\\n [Time: (617.54, 617.72) Text:(for)]\\n [Time: (617.72, 617.87) Text:(from,)]\\n [Time: (617.87, 618.2) Text:(I)]\\n [Time: (618.2, 618.44) Text:(also)]\\n [Time: (618.44, 618.72) Text:(decided)]\\n [Time: (618.72, 618.98) Text:(to)]\\n [Time: (618.98, 619.22) Text:(quickly)]\\n [Time: (619.22, 619.52) Text:(train)]\\n [Time: (619.52, 619.74) Text:(a)]\\n [Time: (619.74, 619.96) Text:(neural)]\\n [Time: (619.96, 620.2) Text:(net)]\\n [Time: (620.2, 620.4) Text:(to)]\\n [Time: (620.4, 620.58) Text:(see)]\\n [Time: (620.58, 620.76) Text:(how)]\\n [Time: (620.76, 620.94) Text:(it)]\\n [Time: (620.94, 621.12) Text:(would)]\\n [Time: (621.12, 621.38) Text:(do)]\\n [Time: (621.38, 621.6) Text:(on)]\\n [Time: (621.6, 621.82) Text:(this)]\\n [Time: (621.82, 622.02) Text:(data)]\\n [Time: (622.02, 622.28) Text:(and)]\\n [Time: (622.28, 622.52) Text:(I)]\\n [Time: (622.52, 622.68) Text:(got)]\\n [Time: (622.68, 622.89) Text:(at)]\\n [Time: (622.89, 623.32) Text:(decent)]\\n [Time: (623.32, 624.0) Text:(83%)]\\n [Time: (624.5, 624.96) Text:(accuracy.)]\\n [Time: (625.22, 625.46) Text:(Now)]\\n [Time: (625.46, 625.78) Text:(to)]\\n [Time: (625.78, 625.98) Text:(end)]\\n [Time: (625.98, 626.2) Text:(this)]\\n [Time: (626.2, 626.5) Text:(video,)]\\n [Time: (626.78, 626.8) Text:(I)]\\n [Time: (626.8, 627.04) Text:(wanted)]\\n [Time: (627.04, 627.26) Text:(to)]\\n [Time: (627.26, 627.4) Text:(see)]\\n [Time: (627.4, 627.56) Text:(if)]\\n [Time: (627.56, 627.74) Text:(my)]\\n [Time: (627.74, 627.96) Text:(model)]\\n [Time: (627.96, 628.26) Text:(could)]\\n [Time: (628.26, 628.56) Text:(predict)]\\n [Time: (628.56, 628.9) Text:(the)]\\n [Time: (628.9, 629.12) Text:(winner)]\\n [Time: (629.22, 629.5) Text:(of)]\\n [Time: (629.5, 629.8) Text:(this)]\\n [Time: (629.8, 630.28) Text:(year's)]\\n [Time: (630.28, 630.68) Text:(Australian)]\\n [Time: (630.68, 631.04) Text:(Open.)]\\n [Time: (631.14, 631.34) Text:(You)]\\n [Time: (631.34, 631.56) Text:(see,)]\\n [Time: (631.74, 631.86) Text:(I)]\\n [Time: (631.86, 632.04) Text:(trained)]\\n [Time: (632.04, 632.26) Text:(my)]\\n [Time: (632.26, 632.62) Text:(models)]\\n [Time: (632.62, 632.94) Text:(with)]\\n [Time: (632.94, 633.18) Text:(10)]\\n [Time: (633.18, 633.32) Text:(as)]\\n [Time: (633.32, 633.58) Text:(much)]\\n [Time: (633.58, 633.96) Text:(as)]\\n [Time: (633.96, 634.1) Text:(up)]\\n [Time: (634.1, 634.4) Text:(until)]\\n [Time: (634.4, 634.57) Text:(the)]\\n [Time: (634.57, 634.96) Text:(December)]\\n [Time: (634.96, 635.62) Text:(2024.)]\\n [Time: (635.88, 636.14) Text:(So)]\\n [Time: (636.14, 636.46) Text:(this)]\\n [Time: (636.46, 636.86) Text:(year's)]\\n [Time: (636.86, 637.22) Text:(Australian)]\\n [Time: (637.22, 637.66) Text:(Open)]\\n [Time: (637.66, 637.94) Text:(was)]\\n [Time: (637.94, 638.12) Text:(not)]\\n [Time: (638.12, 638.26) Text:(in)]\\n [Time: (638.26, 638.36) Text:(my)]\\n [Time: (638.36, 638.6) Text:(data)]\\n [Time: (638.6, 638.8) Text:(set.)]\\n [Time: (639.1, 639.32) Text:(And)]\\n [Time: (639.32, 639.56) Text:(out)]\\n [Time: (639.56, 639.7) Text:(of)]\\n [Time: (639.7, 639.88) Text:(the)]\\n [Time: (639.88, 640.84) Text:(116)]\\n [Time: (640.84, 641.34) Text:(matches,)]\\n [Time: (641.44, 641.62) Text:(I)]\\n [Time: (641.62, 641.82) Text:(could)]\\n [Time: (641.82, 642.22) Text:(find)]\\n [Time: (642.22, 642.54) Text:(my)]\\n [Time: (642.54, 642.88) Text:(model)]\\n [Time: (642.88, 643.42) Text:(correctly)]\\n [Time: (643.42, 644.02) Text:(predicted)]\\n [Time: (644.02, 645.14) Text:(99)]\\n [Time: (645.14, 645.4) Text:(of)]\\n [Time: (645.4, 645.6) Text:(them)]\\n [Time: (645.6, 645.88) Text:(and)]\\n [Time: (645.88, 646.16) Text:(got)]\\n [Time: (646.16, 646.48) Text:(only)]\\n [Time: (646.48, 647.02) Text:(17)]\\n [Time: (647.02, 647.36) Text:(wrong)]\\n [Time: (647.36, 647.64) Text:(and)]\\n [Time: (647.64, 648.12) Text:(hence)]\\n [Time: (648.12, 648.44) Text:(has)]\\n [Time: (648.44, 648.62) Text:(an)]\\n [Time: (648.62, 649.04) Text:(accuracy)]\\n [Time: (649.16, 649.56) Text:(of)]\\n [Time: (649.56, 650.2) Text:(85%)]\\n [Time: (650.68, 651.04) Text:(on)]\\n [Time: (651.04, 651.34) Text:(this)]\\n [Time: (651.34, 651.72) Text:(year's)]\\n [Time: (651.72, 652.08) Text:(Australian)]\\n [Time: (652.08, 652.42) Text:(Open.)]\\n [Time: (652.6, 652.72) Text:(More)]\\n [Time: (652.72, 653.26) Text:(importantly,)]\\n [Time: (653.56, 653.6) Text:(it)]\\n [Time: (653.6, 654.12) Text:(correctly)]\\n [Time: (654.12, 654.66) Text:(predicted)]\\n [Time: (654.66, 655.06) Text:(that)]\\n [Time: (655.06, 655.4) Text:(Jannick)]\\n [Time: (655.4, 655.76) Text:(Center)]\\n [Time: (655.76, 656.02) Text:(would)]\\n [Time: (656.02, 656.28) Text:(win)]\\n [Time: (656.28, 656.82) Text:(every)]\\n [Time: (656.82, 657.18) Text:(single)]\\n [Time: (657.18, 657.5) Text:(one)]\\n [Time: (657.5, 657.52) Text:(of)]\\n [Time: (657.52, 657.68) Text:(his)]\\n [Time: (657.68, 658.08) Text:(matches.)]\\n [Time: (658.32, 658.44) Text:(So)]\\n [Time: (658.44, 658.56) Text:(my)]\\n [Time: (658.56, 658.88) Text:(model)]\\n [Time: (658.88, 659.44) Text:(correctly)]\\n [Time: (659.44, 660.0) Text:(predicted)]\\n [Time: (660.0, 660.4) Text:(the)]\\n [Time: (660.4, 660.7) Text:(winner)]\\n [Time: (660.7, 660.98) Text:(of)]\\n [Time: (660.98, 661.07) Text:(a)]\\n [Time: (661.07, 661.4) Text:(Grand)]\\n [Time: (661.4, 661.72) Text:(slam,)]\\n [Time: (662.1, 662.14) Text:(which)]\\n [Time: (662.14, 662.44) Text:(is)]\\n [Time: (662.44, 662.66) Text:(pretty)]\\n [Time: (662.66, 662.98) Text:(sick)]\\n [Time: (662.98, 663.18) Text:(if)]\\n [Time: (663.18, 663.34) Text:(you)]\\n [Time: (663.34, 663.48) Text:(ask)]\\n [Time: (663.48, 663.68) Text:(me.)]\\n [Time: (663.86, 663.88) Text:(I)]\\n [Time: (663.88, 664.1) Text:(had)]\\n [Time: (664.1, 664.38) Text:(a)]\\n [Time: (664.38, 664.52) Text:(lot)]\\n [Time: (664.52, 664.68) Text:(of)]\\n [Time: (664.68, 664.84) Text:(fun)]\\n [Time: (664.84, 665.02) Text:(with)]\\n [Time: (665.02, 665.22) Text:(this)]\\n [Time: (665.22, 665.44) Text:(video.)]\\n [Time: (665.68, 665.82) Text:(So)]\\n [Time: (665.82, 666.04) Text:(if)]\\n [Time: (666.04, 666.16) Text:(you)]\\n [Time: (666.16, 666.32) Text:(want)]\\n [Time: (666.32, 666.52) Text:(me)]\\n [Time: (666.52, 666.68) Text:(to)]\\n [Time: (666.68, 666.88) Text:(try)]\\n [Time: (666.88, 667.04) Text:(to)]\\n [Time: (667.04, 667.36) Text:(predict)]\\n [Time: (667.36, 667.7) Text:(this)]\\n [Time: (667.7, 668.04) Text:(year's)]\\n [Time: (668.04, 668.56) Text:(Wimmelon)]\\n [Time: (668.56, 668.94) Text:(champion)]\\n [Time: (668.94, 669.4) Text:(using)]\\n [Time: (669.4, 669.96) Text:(XG)]\\n [Time: (669.96, 670.18) Text:(Boost)]\\n [Time: (670.18, 670.38) Text:(from)]\\n [Time: (670.38, 670.78) Text:(scratch,)]\\n [Time: (671.02, 671.16) Text:(like)]\\n [Time: (671.16, 671.3) Text:(the)]\\n [Time: (671.3, 671.52) Text:(video)]\\n [Time: (671.54, 671.8) Text:(and)]\\n [Time: (671.8, 672.1) Text:(comment)]\\n [Time: (672.1, 672.32) Text:(put)]\\n [Time: (672.32, 672.42) Text:(a)]\\n [Time: (672.42, 672.56) Text:(little)]\\n [Time: (672.56, 672.8) Text:(below.)]\\n [Time: (672.98, 673.12) Text:(If)]\\n [Time: (673.12, 673.42) Text:(50)]\\n [Time: (673.42, 673.78) Text:(people)]\\n [Time: (673.78, 674.24) Text:(comment)]\\n [Time: (674.24, 674.46) Text:(put)]\\n [Time: (674.46, 674.62) Text:(a)]\\n [Time: (674.62, 674.68) Text:(little,)]\\n [Time: (675.0, 675.28) Text:(I)]\\n [Time: (675.28, 675.5) Text:(guess)]\\n [Time: (675.5, 675.7) Text:(I'll)]\\n [Time: (675.7, 675.84) Text:(make)]\\n [Time: (675.84, 676.0) Text:(a)]\\n [Time: (676.0, 676.18) Text:(second)]\\n [Time: (676.18, 676.42) Text:(part.)]\\n [Time: (676.52, 676.72) Text:(Hope)]\\n [Time: (676.72, 676.86) Text:(you)]\\n [Time: (676.86, 677.12) Text:(enjoyed)]\\n [Time: (677.12, 677.5) Text:(it)]\\n [Time: (677.5, 677.72) Text:(and)]\\n [Time: (677.72, 678.06) Text:(I'll)]\\n [Time: (678.06, 678.18) Text:(see)]\\n [Time: (678.18, 678.46) Text:(you)]\\n [Time: (678.46, 678.64) Text:(in)]\\n [Time: (678.64, 678.74) Text:(the)]\\n [Time: (678.74, 678.94) Text:(next)]\\n [Time: (678.94, 679.12) Text:(one.)]\\n \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analiza Transkrypcji\n",
    "Sprawdzę modele jakie znam aby znaleźć te reklamy"
   ],
   "id": "7b59fe30f1ca86b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Google Gemini\n",
    "- Kiedyś już korzystałem z tego modelu"
   ],
   "id": "bbcea1b56ca1d265"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:42:00.211689Z",
     "start_time": "2025-04-12T07:41:57.663238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inicjalizacja Api\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyDQrnZwXb0mVx0sViSweNKs_9gWsH9T-u0\")"
   ],
   "id": "49ce0ff9eefdcdad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:42:01.517434Z",
     "start_time": "2025-04-12T07:42:00.289903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys_instruct = \"\"\"\n",
    "    Your task is to detect sponsored content within a youtube video based on the timestamps of its English audio track. The audio track will be provided word by word in the format: [Time: (0.18, 0.56) Text:(Word1)]\\n [Time: (0.18, 0.56) Text:(Word2)]\\n.\n",
    "\n",
    "    Sponsored content is defined as instances where the YouTuber shifts the topic of their video to advertise or promote a product.\n",
    "\n",
    "    You need to identify and mark the entire timestamp range of this sponsored content. Advertisements often span multiple timestamps, so please ensure you capture the entire segment from the beginning to the end of the sponsored segment.\n",
    "\n",
    "    Pay attention to keywords and phrases such as:\n",
    "    sponsoring, sponsor, sponsor of our video, our code, and similar indications of sponsorship.\n",
    "\n",
    "    Only return the detected sponsored content in the following format:\n",
    "    300,325|452,321\n",
    "    \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=text,\n",
    "        config=types.GenerateContentConfig(\n",
    "            max_output_tokens=500,\n",
    "            temperature=0.1,\n",
    "            system_instruction=sys_instruct\n",
    "        )\n",
    ")\n",
    "\n",
    "response.text"
   ],
   "id": "c58802645a4532e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'413.96,472.66'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "W materiale który mamy https://www.youtube.com/watch?v=LkJpNLIaeVk&t=417s model gubi parę sekund ale znalazł reklamę co jest Git tam to się zaczyna od 417 do 477",
   "id": "2790100d1165ef0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T07:42:01.632001Z",
     "start_time": "2025-04-12T07:42:01.607616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "response_text = response.text.split('|')\n",
    "response_text = [a.split(',') for a in response_text]\n",
    "response_text"
   ],
   "id": "e94e60599aa778bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['413.96', '472.66']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "95d41fd26fddfaea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
